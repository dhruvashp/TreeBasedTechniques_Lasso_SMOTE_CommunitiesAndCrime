{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW4\n",
    "1g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "df = pd.read_csv('Final_Imputed_Whole.csv',index_col=0)\n",
    "df_train = df.iloc[0:1495,:]\n",
    "df_test = df.iloc[1495:1994,:]\n",
    "df_test.reset_index(drop=True,inplace=True)\n",
    "X = df_train.drop(columns=['ViolentCrimesPerPop'])\n",
    "X_final_test = df_test.drop(columns=['ViolentCrimesPerPop'])\n",
    "y = df_train['ViolentCrimesPerPop']\n",
    "y_final_test = df_test['ViolentCrimesPerPop']\n",
    "print(X)\n",
    "print(y)\n",
    "print(X_final_test)\n",
    "print(y_final_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of lambda or alpha will be selected from the following set of values:\n",
    "{5*10^-3,5*10^-2,5*10^-1,5*10^0,5*10^1}\n",
    "Thus we'll select lambda/alpha that corresponds to the least CV error\n",
    "\n",
    "We'll use 5-fold cross validation on the training set, compute average MSE over these 5-folds for each lambda, select lambda giving least MSE\n",
    "\n",
    "Once lambda selected, we'll refit model on the entire training data using that lambda, obtain MSE over test finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.array([5*(10**(-3)),5*(10**(-2)),5*(10**(-1)),5*(10**(0)),5*(10**(1))])\n",
    "alpha_pointer = np.arange(0,5)\n",
    "alpha_mse_sum = np.zeros(5)\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    i=0\n",
    "    for i in alpha_pointer:\n",
    "        ridge_reg = Ridge(alpha=alpha[i],fit_intercept=True,normalize=False) #Already Normalized, Fit Intercept\n",
    "        ridge_fit = ridge_reg.fit(X_train,y_train)\n",
    "        y_predicted = ridge_fit.predict(X_test)\n",
    "        mse_interim = mean_squared_error(y_test,y_predicted)\n",
    "        alpha_mse_sum[i] = alpha_mse_sum[i] + mse_interim #alpha_mse_sum stores mse in indices corresponding to alphas, and \n",
    "                                                          #it keeps summing mse's for each alpha over every single fold, \n",
    "                                                          #final mse obtained by dividing by 5 \n",
    "                \n",
    "final_alpha_mse = alpha_mse_sum/5 #alpha mse were summed, dividing by 5 gives us the average mse for each alpha over 5-folds\n",
    "\n",
    "\n",
    "selected_alpha_index = np.argmin(final_alpha_mse) #returns index with minimal mse, corresponding to index for alpha\n",
    "\n",
    "print('The alpha selected, via 5-fold CV is : \\n',alpha[selected_alpha_index])\n",
    "\n",
    "final_ridge = Ridge(alpha=alpha[selected_alpha_index],fit_intercept=True,normalize=False)\n",
    "\n",
    "final_fit = final_ridge.fit(X,y) #fitting on the entire training set\n",
    "\n",
    "y_final_predicted = final_fit.predict(X_final_test)\n",
    "\n",
    "print('The final y predicted over test set with the best selected alpha/lambda is : \\n',y_final_predicted)\n",
    "print('The y_test for comparison is : \\n',y_final_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_final_test,y_final_predicted)\n",
    "\n",
    "print('The corresponding MSE is : \\n',final_mse)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus test MSE for Ridge Regression is 0.017\n",
    "Test MSE for Linear Regression was 0.056\n",
    "\n",
    "Thus Ridge Regression, with lambda = 5 performs better than Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
