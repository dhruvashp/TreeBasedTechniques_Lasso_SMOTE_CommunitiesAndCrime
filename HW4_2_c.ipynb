{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW4\n",
    "2c\n",
    "\n",
    "We have assumed that the number of predictors, m, for the random forests is constant and we don't need to compare the results (various relevant results) for different values of m even though it could be done quite simply by using a loop\n",
    "\n",
    "Total original predictors we have are 170\n",
    "We will choose m = sqrt(p) = 13 (approximately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class  aa_000    ab_000        ac_000      ad_000  ae_000  af_000  \\\n",
      "0          0   76698  0.000000  2.130706e+09  280.000000     0.0     0.0   \n",
      "1          0   33058  0.645959  0.000000e+00  638.509566     0.0     0.0   \n",
      "2          0   41040  0.644207  2.280000e+02  100.000000     0.0     0.0   \n",
      "3          0      12  0.000000  7.000000e+01   66.000000     0.0    10.0   \n",
      "4          0   60874  0.035666  1.368000e+03  458.000000     0.0     0.0   \n",
      "...      ...     ...       ...           ...         ...     ...     ...   \n",
      "59995      0  153002  0.355823  6.640000e+02  186.000000     0.0     0.0   \n",
      "59996      0    2286  0.000000  2.130707e+09  224.000000     0.0     0.0   \n",
      "59997      0     112  0.000000  2.130706e+09   18.000000     0.0     0.0   \n",
      "59998      0   80292  0.117141  2.130706e+09  494.000000     0.0     0.0   \n",
      "59999      0   40222  0.001512  6.980000e+02  628.000000     0.0     0.0   \n",
      "\n",
      "       ag_000  ag_001  ag_002  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
      "0         0.0     0.0     0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
      "1         0.0     0.0     0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
      "2         0.0     0.0     0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
      "3         0.0     0.0     0.0  ...      240.0      46.0       58.0       44.0   \n",
      "4         0.0     0.0     0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
      "...       ...     ...     ...  ...        ...       ...        ...        ...   \n",
      "59995     0.0     0.0     0.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
      "59996     0.0     0.0     0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
      "59997     0.0     0.0     0.0  ...      792.0     386.0      452.0      144.0   \n",
      "59998     0.0     0.0     0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
      "59999     0.0     0.0     0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
      "0       339156.0  157956.0   73224.0       0.0     0.0     0.0  \n",
      "1       133654.0   81140.0   97576.0    1500.0     0.0     0.0  \n",
      "2       320746.0  158022.0   95128.0     514.0     0.0     0.0  \n",
      "3           10.0       0.0       0.0       0.0     4.0    32.0  \n",
      "4       286954.0  311560.0  433954.0    1218.0     0.0     0.0  \n",
      "...          ...       ...       ...       ...     ...     ...  \n",
      "59995  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
      "59996      136.0       0.0       0.0       0.0     0.0     0.0  \n",
      "59997      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
      "59998   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
      "59999   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
      "\n",
      "[60000 rows x 171 columns]\n",
      "       class  aa_000    ab_000        ac_000  ad_000  ae_000  af_000  ag_000  \\\n",
      "0          0      60  0.000000  2.000000e+01    12.0     0.0     0.0     0.0   \n",
      "1          0      82  0.000000  6.800000e+01    40.0     0.0     0.0     0.0   \n",
      "2          0   66002  2.000000  2.120000e+02   112.0     0.0     0.0     0.0   \n",
      "3          0   59816  0.638151  1.010000e+03   936.0     0.0     0.0     0.0   \n",
      "4          0    1814  0.108426  1.560000e+02   140.0     0.0     0.0     0.0   \n",
      "...      ...     ...       ...           ...     ...     ...     ...     ...   \n",
      "15995      0   81852  0.709256  2.130706e+09   892.0     0.0     0.0     0.0   \n",
      "15996      0      18  0.000000  5.200000e+01    46.0     8.0    26.0     0.0   \n",
      "15997      0   79636  0.063588  1.670000e+03  1518.0     0.0     0.0     0.0   \n",
      "15998      0     110  0.000000  3.600000e+01    32.0     0.0     0.0     0.0   \n",
      "15999      0       8  0.000000  6.000000e+00     4.0     2.0     2.0     0.0   \n",
      "\n",
      "       ag_001  ag_002  ...    ee_002    ee_003    ee_004    ee_005     ee_006  \\\n",
      "0         0.0     0.0  ...    1098.0     138.0     412.0     654.0       78.0   \n",
      "1         0.0     0.0  ...    1068.0     276.0    1620.0     116.0       86.0   \n",
      "2         0.0     0.0  ...  495076.0  380368.0  440134.0  269556.0  1315022.0   \n",
      "3         0.0     0.0  ...  540820.0  243270.0  483302.0  485332.0   431376.0   \n",
      "4         0.0     0.0  ...    7646.0    4144.0   18466.0   49782.0     3176.0   \n",
      "...       ...     ...  ...       ...       ...       ...       ...        ...   \n",
      "15995     0.0     0.0  ...  632658.0  273242.0  510354.0  373918.0   349840.0   \n",
      "15996     0.0     0.0  ...     266.0      44.0      46.0      14.0        2.0   \n",
      "15997     0.0     0.0  ...  806832.0  449962.0  778826.0  581558.0   375498.0   \n",
      "15998     0.0     0.0  ...     588.0     210.0     180.0     544.0     1004.0   \n",
      "15999     0.0     0.0  ...      46.0      10.0      48.0      14.0       42.0   \n",
      "\n",
      "         ee_007    ee_008   ee_009  ef_000  eg_000  \n",
      "0          88.0       0.0      0.0     0.0     0.0  \n",
      "1         462.0       0.0      0.0     0.0     0.0  \n",
      "2      153680.0     516.0      0.0     0.0     0.0  \n",
      "3      210074.0  281662.0   3232.0     0.0     0.0  \n",
      "4         482.0      76.0      0.0     0.0     0.0  \n",
      "...         ...       ...      ...     ...     ...  \n",
      "15995  317840.0  960024.0  25566.0     0.0     0.0  \n",
      "15996       0.0       0.0      0.0     0.0     0.0  \n",
      "15997  222866.0  358934.0  19548.0     0.0     0.0  \n",
      "15998    1338.0      74.0      0.0     0.0     0.0  \n",
      "15999      46.0       0.0      0.0     0.0     0.0  \n",
      "\n",
      "[16000 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_train = pd.read_csv('aps_train.csv',index_col=0)\n",
    "df_test = pd.read_csv('aps_test.csv',index_col=0)\n",
    "\n",
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aa_000    ab_000        ac_000      ad_000  ae_000  af_000  ag_000  \\\n",
      "0       76698  0.000000  2.130706e+09  280.000000     0.0     0.0     0.0   \n",
      "1       33058  0.645959  0.000000e+00  638.509566     0.0     0.0     0.0   \n",
      "2       41040  0.644207  2.280000e+02  100.000000     0.0     0.0     0.0   \n",
      "3          12  0.000000  7.000000e+01   66.000000     0.0    10.0     0.0   \n",
      "4       60874  0.035666  1.368000e+03  458.000000     0.0     0.0     0.0   \n",
      "...       ...       ...           ...         ...     ...     ...     ...   \n",
      "59995  153002  0.355823  6.640000e+02  186.000000     0.0     0.0     0.0   \n",
      "59996    2286  0.000000  2.130707e+09  224.000000     0.0     0.0     0.0   \n",
      "59997     112  0.000000  2.130706e+09   18.000000     0.0     0.0     0.0   \n",
      "59998   80292  0.117141  2.130706e+09  494.000000     0.0     0.0     0.0   \n",
      "59999   40222  0.001512  6.980000e+02  628.000000     0.0     0.0     0.0   \n",
      "\n",
      "       ag_001  ag_002  ag_003  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
      "0         0.0     0.0     0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
      "1         0.0     0.0     0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
      "2         0.0     0.0     0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
      "3         0.0     0.0   318.0  ...      240.0      46.0       58.0       44.0   \n",
      "4         0.0     0.0     0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
      "...       ...     ...     ...  ...        ...       ...        ...        ...   \n",
      "59995     0.0     0.0  2564.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
      "59996     0.0     0.0     0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
      "59997     0.0     0.0     0.0  ...      792.0     386.0      452.0      144.0   \n",
      "59998     0.0     0.0     0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
      "59999     0.0     0.0     0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
      "0       339156.0  157956.0   73224.0       0.0     0.0     0.0  \n",
      "1       133654.0   81140.0   97576.0    1500.0     0.0     0.0  \n",
      "2       320746.0  158022.0   95128.0     514.0     0.0     0.0  \n",
      "3           10.0       0.0       0.0       0.0     4.0    32.0  \n",
      "4       286954.0  311560.0  433954.0    1218.0     0.0     0.0  \n",
      "...          ...       ...       ...       ...     ...     ...  \n",
      "59995  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
      "59996      136.0       0.0       0.0       0.0     0.0     0.0  \n",
      "59997      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
      "59998   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
      "59999   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
      "\n",
      "[60000 rows x 170 columns]\n",
      "       aa_000    ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
      "0          60  0.000000  2.000000e+01    12.0     0.0     0.0     0.0     0.0   \n",
      "1          82  0.000000  6.800000e+01    40.0     0.0     0.0     0.0     0.0   \n",
      "2       66002  2.000000  2.120000e+02   112.0     0.0     0.0     0.0     0.0   \n",
      "3       59816  0.638151  1.010000e+03   936.0     0.0     0.0     0.0     0.0   \n",
      "4        1814  0.108426  1.560000e+02   140.0     0.0     0.0     0.0     0.0   \n",
      "...       ...       ...           ...     ...     ...     ...     ...     ...   \n",
      "15995   81852  0.709256  2.130706e+09   892.0     0.0     0.0     0.0     0.0   \n",
      "15996      18  0.000000  5.200000e+01    46.0     8.0    26.0     0.0     0.0   \n",
      "15997   79636  0.063588  1.670000e+03  1518.0     0.0     0.0     0.0     0.0   \n",
      "15998     110  0.000000  3.600000e+01    32.0     0.0     0.0     0.0     0.0   \n",
      "15999       8  0.000000  6.000000e+00     4.0     2.0     2.0     0.0     0.0   \n",
      "\n",
      "       ag_002    ag_003  ...    ee_002    ee_003    ee_004    ee_005  \\\n",
      "0         0.0    2682.0  ...    1098.0     138.0     412.0     654.0   \n",
      "1         0.0       0.0  ...    1068.0     276.0    1620.0     116.0   \n",
      "2         0.0  199486.0  ...  495076.0  380368.0  440134.0  269556.0   \n",
      "3         0.0       0.0  ...  540820.0  243270.0  483302.0  485332.0   \n",
      "4         0.0       0.0  ...    7646.0    4144.0   18466.0   49782.0   \n",
      "...       ...       ...  ...       ...       ...       ...       ...   \n",
      "15995     0.0       0.0  ...  632658.0  273242.0  510354.0  373918.0   \n",
      "15996     0.0       0.0  ...     266.0      44.0      46.0      14.0   \n",
      "15997     0.0       0.0  ...  806832.0  449962.0  778826.0  581558.0   \n",
      "15998     0.0       0.0  ...     588.0     210.0     180.0     544.0   \n",
      "15999     0.0       0.0  ...      46.0      10.0      48.0      14.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008   ee_009  ef_000  eg_000  \n",
      "0           78.0      88.0       0.0      0.0     0.0     0.0  \n",
      "1           86.0     462.0       0.0      0.0     0.0     0.0  \n",
      "2      1315022.0  153680.0     516.0      0.0     0.0     0.0  \n",
      "3       431376.0  210074.0  281662.0   3232.0     0.0     0.0  \n",
      "4         3176.0     482.0      76.0      0.0     0.0     0.0  \n",
      "...          ...       ...       ...      ...     ...     ...  \n",
      "15995   349840.0  317840.0  960024.0  25566.0     0.0     0.0  \n",
      "15996        2.0       0.0       0.0      0.0     0.0     0.0  \n",
      "15997   375498.0  222866.0  358934.0  19548.0     0.0     0.0  \n",
      "15998     1004.0    1338.0      74.0      0.0     0.0     0.0  \n",
      "15999       42.0      46.0       0.0      0.0     0.0     0.0  \n",
      "\n",
      "[16000 rows x 170 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns=['class'])\n",
    "X_test = df_test.drop(columns=['class'])\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "59995    0\n",
      "59996    0\n",
      "59997    0\n",
      "59998    0\n",
      "59999    0\n",
      "Name: class, Length: 60000, dtype: int64\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "15995    0\n",
      "15996    0\n",
      "15997    0\n",
      "15998    0\n",
      "15999    0\n",
      "Name: class, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['class']\n",
    "y_test = df_test['class']\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "59995    0\n",
      "59996    0\n",
      "59997    0\n",
      "59998    0\n",
      "59999    0\n",
      "Name: class, Length: 60000, dtype: int64\n",
      "[0 0 0 ... 0 0 0]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "15995    0\n",
      "15996    0\n",
      "15997    0\n",
      "15998    0\n",
      "15999    0\n",
      "Name: class, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100,max_features='sqrt',bootstrap=True,oob_score=True) # draws all samples \n",
    "                                                                                                    # from train\n",
    "forest_fit = forest.fit(X_train,y_train)\n",
    "y_train_predicted = forest_fit.predict(X_train)\n",
    "y_test_predicted = forest_fit.predict(X_test)\n",
    "\n",
    "print(y_train_predicted)\n",
    "print(y_train)\n",
    "\n",
    "print(y_test_predicted)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above outputs show the predicted arrays for class above the true class series for train and test set respectively, obtained via the forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of Bag and Test Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is : \n",
      " 0.7499999999999951 %\n",
      "oob error is : \n",
      " 0.6283333333333307 %\n"
     ]
    }
   ],
   "source": [
    "test_error = (1-forest_fit.score(X_test, y_test))*100\n",
    "oob_error = (1-forest_fit.oob_score_)*100\n",
    "\n",
    "print('Test error is : \\n',test_error,'%')\n",
    "print('oob error is : \\n',oob_error,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the errors in % are less than 1 and are extremely low. In general due to the class imbalance being as bad as 2% this is expected, as even if we classify all samples to 0, the error would still be less than 2% as we have such large class imbalance\n",
    "\n",
    "The oob error, obtained above, does a decent job of estimating the test error but still somewhat underestimates it\n",
    "\n",
    "Next, to get an idea of how good our classifier is, we get its Confusion Matrix\n",
    "\n",
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59000     0]\n",
      " [    1   999]]\n",
      "[[15609    16]\n",
      " [  104   271]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_train = confusion_matrix(y_train,y_train_predicted)\n",
    "conf_test = confusion_matrix(y_test,y_test_predicted)\n",
    "\n",
    "print(conf_train)\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix are as shown above\n",
    "00 True Negative\n",
    "10 False Negative\n",
    "11 True Positive\n",
    "01 False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0        59000            0\n",
      "Actually 1            1          999\n",
      "Test Confusion is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0        15609           16\n",
      "Actually 1          104          271\n"
     ]
    }
   ],
   "source": [
    "index_row = ['Actually 0','Actually 1']\n",
    "header_col = ['Predicted 0','Predicted 1']\n",
    "\n",
    "train_conf = pd.DataFrame(conf_train,index=index_row,columns=header_col)\n",
    "test_conf = pd.DataFrame(conf_test,index=index_row,columns=header_col)\n",
    "\n",
    "print('Training Confusion is : \\n',train_conf)\n",
    "print('Test Confusion is : \\n',test_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing on Test,\n",
    "Almost all true 0's are correctly classified as 0's\n",
    "Quite a few true 1's are predicted/classified as 0's\n",
    "\n",
    "Ratio of (actually 1, predicted 1) to (total true 1's in test) is :\n",
    "\n",
    "271/(271+104) = 72.2 %\n",
    "Thus approximately 72 % of all 1's in the test set are correctly predicted as 1, rest are predicted as 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            TPR       FPR\n",
      "0    0.00266667         0\n",
      "1     0.0106667         0\n",
      "2     0.0186667         0\n",
      "3         0.032         0\n",
      "4     0.0453333         0\n",
      "..          ...       ...\n",
      "96     0.978667  0.034112\n",
      "97        0.984   0.04096\n",
      "98     0.994667  0.052992\n",
      "99     0.994667   0.09184\n",
      "100           1         1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "threshold_range = np.arange(0,1.01,0.01)\n",
    "pointer = np.arange(0,np.size(threshold_range))\n",
    "y_test_prob = forest_fit.predict_proba(X_test)\n",
    "y_test_prob_0 = y_test_prob[:,0]\n",
    "ROC_df = pd.DataFrame(index=np.arange(0,np.size(threshold_range)),columns=['TPR','FPR'])\n",
    "\n",
    "i=0\n",
    "for i in pointer:\n",
    "    y_test_predicted_new = (y_test_prob_0 <= threshold_range[i]).astype(int)\n",
    "    conf_test_new = confusion_matrix(y_test,y_test_predicted_new)\n",
    "    TPR = conf_test_new[1][1]/(conf_test_new[1][1]+conf_test_new[1][0])\n",
    "    FPR = conf_test_new[0][1]/(conf_test_new[0][1]+conf_test_new[0][0])\n",
    "    ROC_df.iloc[i,0]=TPR\n",
    "    ROC_df.iloc[i,1]=FPR    \n",
    "    \n",
    "print(ROC_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold = index/100\n",
    "Also as class imbalance is extreme, we have FPR suddenly rising to 1 when threshold is 1 as the probability of being in class 0 is too high (close to being 1 in quite a few cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11d3143b0c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(data=ROC_df,x='FPR',y='TPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is test ROC\n",
    "As can be seen it follows typical ROC curve, also jump to 1,1 is immediate from the FPR point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TPR        FPR\n",
      "0    0.031          0\n",
      "1    0.054          0\n",
      "2    0.098          0\n",
      "3    0.146          0\n",
      "4    0.199          0\n",
      "..     ...        ...\n",
      "96       1  0.0196441\n",
      "97       1  0.0244407\n",
      "98       1  0.0336271\n",
      "99       1  0.0615763\n",
      "100      1          1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train_prob = forest_fit.predict_proba(X_train)\n",
    "y_train_prob_0 = y_train_prob[:,0]\n",
    "ROC_train_df = pd.DataFrame(index=np.arange(0,np.size(threshold_range)),columns=['TPR','FPR'])\n",
    "\n",
    "i=0\n",
    "for i in pointer:\n",
    "    y_train_predicted_new = (y_train_prob_0 <= threshold_range[i]).astype(int)\n",
    "    conf_train_new = confusion_matrix(y_train,y_train_predicted_new)\n",
    "    TPR = conf_train_new[1][1]/(conf_train_new[1][1]+conf_train_new[1][0])\n",
    "    FPR = conf_train_new[0][1]/(conf_train_new[0][1]+conf_train_new[0][0])\n",
    "    ROC_train_df.iloc[i,0]=TPR\n",
    "    ROC_train_df.iloc[i,1]=FPR    \n",
    "    \n",
    "print(ROC_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x11d33398fc8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(data=ROC_train_df,x='FPR',y='TPR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing ROC curves for Train and Test, Train ROC implies a much better model than Test, even though test implies a pretty good model (based on area under the ROC curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test AUC is : \n",
      " 0.9946333013333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_test = metrics.auc(ROC_df['FPR'],ROC_df['TPR'])\n",
    "\n",
    "print('The test AUC is : \\n', auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train AUC is : \n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "auc_train = metrics.auc(ROC_train_df['FPR'],ROC_train_df['TPR'])\n",
    "\n",
    "print('The train AUC is : \\n', auc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen train AUC is 1, and test AUC is pretty close to 1. Thus despite the fact that only 72 % positive imbalanced class members have been correctly classified, this model is pretty good given the extremely imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Test Misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification for Training set out of 60000 is : \n",
      " 1\n",
      "Misclassification for Test set out of 16000 is : \n",
      " 120\n"
     ]
    }
   ],
   "source": [
    "train_mis = 0\n",
    "for i in np.arange(0,60000):\n",
    "    if y_train_predicted[i] != y_train[i]:\n",
    "        train_mis = train_mis + 1\n",
    "\n",
    "test_mis = 0\n",
    "for i in np.arange(0,16000):\n",
    "    if y_test_predicted[i] != y_test[i]:\n",
    "        test_mis = test_mis + 1\n",
    "        \n",
    "print('Misclassification for Training set out of 60000 is : \\n',train_mis)\n",
    "print('Misclassification for Test set out of 16000 is : \\n',test_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion :\n",
    "Other than issue of only 72 % class 1 samples being correctly predicted (test data), the model does seem a good one. Additionally for an imbalance of 2% without utilizing any class balancing technique, this might be the best one could expect a model to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
