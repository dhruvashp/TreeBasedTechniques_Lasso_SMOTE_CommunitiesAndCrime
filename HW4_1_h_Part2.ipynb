{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW4\n",
    "1h\n",
    "Standardized Predictors/Features\n",
    "\n",
    "While there are many ways of standardizing, we'll standardize with zero mean and unit variance. For each predictor column, an\n",
    "entry in a predictor column will be change to a new entry where the new entry will be obtained by subtracting mean from the old entry and then dividing by the standard deviation of the predictor column (square root of the average value of the squared deviation of a predictor entry from that predictor's mean)\n",
    "\n",
    "Additionally we WON'T standardize similarly the output or the target vector. ONLY predictors will be standardized. The data is already normalized.\n",
    "\n",
    "\n",
    "\n",
    "When to Standardize the dataset?\n",
    "To answer this question we've assumed the following:\n",
    "\n",
    "The dataset, collectively was normalized (train+test) and then that 'data' was considered 'normalized'\n",
    "\n",
    "Following in direct congruence, we will standardize the whole dataset first (train+test) and then consider all portions of the dataset, wherever used, appropriately 'standardized'\n",
    "\n",
    "Thus standardization will only be performed on the ENTIRE dataset, only ONCE. It WILL NOT be performed seperately for train or test and will also NOT be performed on the seperate CV iteration train and test sets.\n",
    "\n",
    "THUS, we will standardize, only ONCE, the WHOLE data, with zero mean and unit variance, and consider sectioned usage of this data as usage of 'standardized data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
      "0       1.043612      -0.814997     -0.630002      0.599578     -0.161288   \n",
      "1      -0.453937      -1.853636     -0.235335     -0.056219      1.418982   \n",
      "2      -0.453937      -0.265129      1.224931     -0.793990      0.078147   \n",
      "3      -0.138663       1.873246      3.237730     -2.761379     -0.161288   \n",
      "4      -0.375118       0.529125     -0.630002      0.804514     -0.304949   \n",
      "...          ...            ...           ...           ...           ...   \n",
      "1989   -0.375118      -0.387322     -0.314269      0.476616     -0.161288   \n",
      "1990   -0.059845       3.034078      1.106531     -1.941633      3.238686   \n",
      "1991    0.807157      -0.570611      0.277731     -0.261155     -0.544384   \n",
      "1992    0.176610       0.284739     -0.472135      0.476616      0.317581   \n",
      "1993    1.122430       1.934343     -0.156402     -1.203862      0.413355   \n",
      "\n",
      "      racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  ...  \\\n",
      "0        0.111765    -0.542791    -0.166286    -0.277923   -0.575886  ...   \n",
      "1       -0.318466    -1.058398     0.669791     0.082518   -0.854996  ...   \n",
      "2       -0.447535    -0.220536    -0.166286    -0.337996   -0.575886  ...   \n",
      "3       -0.189397     0.552875     0.042733     0.022445   -1.189929  ...   \n",
      "4       -0.404512    -0.284987    -0.793343    -0.638364   -0.352597  ...   \n",
      "...           ...          ...          ...          ...         ...  ...   \n",
      "1989     0.068742     0.037268     0.112406     0.082518   -0.687530  ...   \n",
      "1990     0.757111     1.712992     2.550963     2.365311   -1.580683  ...   \n",
      "1991     0.455950    -0.478340     0.042733    -0.157776    0.652200  ...   \n",
      "1992    -0.189397     1.004032     1.714887     1.764576   -0.073487  ...   \n",
      "1993     2.693151     0.488424     0.878810     0.382886   -1.413217  ...   \n",
      "\n",
      "      LandArea   PopDens  PctUsePubTrans  PolicCars  PolicOperBudg  \\\n",
      "0     0.500488  0.133699        0.167316  -1.174339      -0.657442   \n",
      "1    -0.413323 -0.555817        1.259032  -0.286536       0.045382   \n",
      "2    -0.504705 -0.112556       -0.618719   0.136369       0.015733   \n",
      "3    -0.413323  0.773964        0.516665   0.301722      -0.017617   \n",
      "4    -0.230561 -0.703570       -0.618719  -0.057226      -0.065332   \n",
      "...        ...       ...             ...        ...            ...   \n",
      "1989 -0.504705  0.232202       -0.487713   0.156862      -0.053733   \n",
      "1990 -0.413323  0.675462        0.167316   0.146993       0.018589   \n",
      "1991  0.134964  0.429206        0.079979  -0.946613      -0.300643   \n",
      "1992 -0.321942  0.724713        0.735008  -1.629789      -1.014240   \n",
      "1993  0.409107  0.330704       -0.487713  -0.946613      -0.657442   \n",
      "\n",
      "      LemasPctPolicOnPatr  LemasGangUnitDeploy  LemasPctOfficDrugUn  \\\n",
      "0                2.338312             0.355791             0.940399   \n",
      "1               -0.015653             0.643640            -0.391447   \n",
      "2                0.140752            -0.146303            -0.391447   \n",
      "3               -0.073854            -0.029633            -0.391447   \n",
      "4                0.048704             0.074733            -0.391447   \n",
      "...                   ...                  ...                  ...   \n",
      "1989             0.043197             0.195023            -0.391447   \n",
      "1990             0.089751             0.357622            -0.391447   \n",
      "1991             0.941523            -2.628195             3.395990   \n",
      "1992             1.057923            -2.628195             0.524197   \n",
      "1993             0.359528             0.355791             3.770572   \n",
      "\n",
      "      PolicBudgPerPop  ViolentCrimesPerPop  \n",
      "0           -0.832653                 0.20  \n",
      "1           -0.109670                 0.67  \n",
      "2            0.128641                 0.43  \n",
      "3            0.001280                 0.12  \n",
      "4           -0.005077                 0.03  \n",
      "...               ...                  ...  \n",
      "1989        -0.038289                 0.09  \n",
      "1990        -0.105793                 0.45  \n",
      "1991         1.285279                 0.23  \n",
      "1992        -0.227529                 0.19  \n",
      "1993        -0.983933                 0.48  \n",
      "\n",
      "[1994 rows x 123 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_normal = pd.read_csv('Final_Imputed_Whole.csv',index_col=0)\n",
    "df_normal_features = df_normal.drop(columns=['ViolentCrimesPerPop'])\n",
    "feature_header = df_normal_features.columns\n",
    "scaler = StandardScaler(with_mean=True,with_std=True)\n",
    "scaler.fit(df_normal_features)\n",
    "standard_features = scaler.transform(df_normal_features)\n",
    "standard_features_df = pd.DataFrame(standard_features,columns=feature_header)\n",
    "target = df_normal['ViolentCrimesPerPop'].to_list()\n",
    "standard_features_df['ViolentCrimesPerPop'] = target\n",
    "df=standard_features_df.copy()\n",
    "print(df) #df is the new standardized whole dataset containing both the features/predictors and the target/prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step, everything else stays exactly same, without any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
      "0       1.043612      -0.814997     -0.630002      0.599578     -0.161288   \n",
      "1      -0.453937      -1.853636     -0.235335     -0.056219      1.418982   \n",
      "2      -0.453937      -0.265129      1.224931     -0.793990      0.078147   \n",
      "3      -0.138663       1.873246      3.237730     -2.761379     -0.161288   \n",
      "4      -0.375118       0.529125     -0.630002      0.804514     -0.304949   \n",
      "...          ...            ...           ...           ...           ...   \n",
      "1490   -0.453937       0.773510     -0.669468     -0.261155      4.052765   \n",
      "1491    0.807157       0.956800     -0.590535     -0.056219      1.562643   \n",
      "1492   -0.375118      -0.631708      3.040397     -2.105582     -0.592271   \n",
      "1493    0.018973       0.406932     -0.669468      0.927476     -0.496497   \n",
      "1494   -0.059845      -0.204033     -0.393202     -0.425104     -0.161288   \n",
      "\n",
      "      racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  ...  \\\n",
      "0        0.111765    -0.542791    -0.166286    -0.277923   -0.575886  ...   \n",
      "1       -0.318466    -1.058398     0.669791     0.082518   -0.854996  ...   \n",
      "2       -0.447535    -0.220536    -0.166286    -0.337996   -0.575886  ...   \n",
      "3       -0.189397     0.552875     0.042733     0.022445   -1.189929  ...   \n",
      "4       -0.404512    -0.284987    -0.793343    -0.638364   -0.352597  ...   \n",
      "...           ...          ...          ...          ...         ...  ...   \n",
      "1490    -0.318466    -0.091634    -1.490074    -0.638364    0.819666  ...   \n",
      "1491     1.187342     0.101719     0.530445     0.382886   -0.966640  ...   \n",
      "1492    -0.576604     0.101719    -0.514651    -0.398070    1.154599  ...   \n",
      "1493    -0.576604    -0.156085    -0.653997    -0.578290   -0.743352  ...   \n",
      "1494     3.682682    -0.349438     0.182079    -0.037629    0.093979  ...   \n",
      "\n",
      "      PolicAveOTWorked  LandArea   PopDens  PctUsePubTrans  PolicCars  \\\n",
      "0            -0.166222  0.500488  0.133699        0.167316  -1.174339   \n",
      "1             0.008026 -0.413323 -0.555817        1.259032  -0.286536   \n",
      "2             0.183565 -0.504705 -0.112556       -0.618719   0.136369   \n",
      "3            -0.202611 -0.413323  0.773964        0.516665   0.301722   \n",
      "4             0.045673 -0.230561 -0.703570       -0.618719  -0.057226   \n",
      "...                ...       ...       ...             ...        ...   \n",
      "1490          0.378788 -0.413323 -0.457315        0.254653  -0.141396   \n",
      "1491          0.800462  0.043583  0.823216       -0.094696  -1.060476   \n",
      "1492         -0.177278 -0.321942 -0.555817       -0.662388   0.068105   \n",
      "1493         -0.113757  0.134964 -0.408063       -0.618719   0.224673   \n",
      "1494          1.874554 -0.596086  3.778285        3.660806  -1.857515   \n",
      "\n",
      "      PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
      "0         -0.657442             2.338312             0.355791   \n",
      "1          0.045382            -0.015653             0.643640   \n",
      "2          0.015733             0.140752            -0.146303   \n",
      "3         -0.017617            -0.073854            -0.029633   \n",
      "4         -0.065332             0.048704             0.074733   \n",
      "...             ...                  ...                  ...   \n",
      "1490      -0.064179            -0.008002            -0.195382   \n",
      "1491      -0.479042             1.756317             0.355791   \n",
      "1492       0.044409            -0.019611            -0.002397   \n",
      "1493       0.028015             0.079904            -0.097251   \n",
      "1494      -1.192640             0.825124            -2.628195   \n",
      "\n",
      "      LemasPctOfficDrugUn  PolicBudgPerPop  \n",
      "0                0.940399        -0.832653  \n",
      "1               -0.391447        -0.109670  \n",
      "2               -0.391447         0.128641  \n",
      "3               -0.391447         0.001280  \n",
      "4               -0.391447        -0.005077  \n",
      "...                   ...              ...  \n",
      "1490            -0.391447        -0.039035  \n",
      "1491             2.147385        -0.076248  \n",
      "1492            -0.391447         0.060716  \n",
      "1493            -0.391447        -0.021538  \n",
      "1494             1.731183        -0.227529  \n",
      "\n",
      "[1495 rows x 122 columns]\n",
      "0       0.20\n",
      "1       0.67\n",
      "2       0.43\n",
      "3       0.12\n",
      "4       0.03\n",
      "        ... \n",
      "1490    0.03\n",
      "1491    0.20\n",
      "1492    0.30\n",
      "1493    0.03\n",
      "1494    0.23\n",
      "Name: ViolentCrimesPerPop, Length: 1495, dtype: float64\n",
      "     population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
      "0     -0.453937      -1.609251     -0.590535      0.640565      0.365468   \n",
      "1     -0.453937       0.529125     -0.195869      0.107730     -0.017627   \n",
      "2     -0.453937       0.345835     -0.551068     -0.671028     -0.496497   \n",
      "3     -0.138663       0.284739     -0.432668      0.681552     -0.304949   \n",
      "4     -0.217482       0.773510      0.080398     -0.015231      0.173920   \n",
      "..          ...            ...           ...           ...           ...   \n",
      "494   -0.375118      -0.387322     -0.314269      0.476616     -0.161288   \n",
      "495   -0.059845       3.034078      1.106531     -1.941633      3.238686   \n",
      "496    0.807157      -0.570611      0.277731     -0.261155     -0.544384   \n",
      "497    0.176610       0.284739     -0.472135      0.476616      0.317581   \n",
      "498    1.122430       1.934343     -0.156402     -1.203862      0.413355   \n",
      "\n",
      "     racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  ...  \\\n",
      "0      -0.404512    -1.767358    -2.117131    -1.479392   -0.017665  ...   \n",
      "1       0.929204     0.359522     0.251752    -0.217849   -1.803972  ...   \n",
      "2       2.047804     2.679756     1.993579     2.485458    0.038157  ...   \n",
      "3      -0.490558    -0.284987    -0.166286    -0.398070   -0.408419  ...   \n",
      "4      -0.189397    -0.284987     0.878810     0.082518   -1.748150  ...   \n",
      "..           ...          ...          ...          ...         ...  ...   \n",
      "494     0.068742     0.037268     0.112406     0.082518   -0.687530  ...   \n",
      "495     0.757111     1.712992     2.550963     2.365311   -1.580683  ...   \n",
      "496     0.455950    -0.478340     0.042733    -0.157776    0.652200  ...   \n",
      "497    -0.189397     1.004032     1.714887     1.764576   -0.073487  ...   \n",
      "498     2.693151     0.488424     0.878810     0.382886   -1.413217  ...   \n",
      "\n",
      "     PolicAveOTWorked  LandArea   PopDens  PctUsePubTrans  PolicCars  \\\n",
      "0            0.225156 -0.504705 -0.014054        2.481753   0.131002   \n",
      "1           -0.164979 -0.504705 -0.260310       -0.618719   0.179910   \n",
      "2            0.218420 -0.504705 -0.260310       -0.706056   0.005410   \n",
      "3           -0.021737 -0.047799 -0.506566       -0.007358  -0.245554   \n",
      "4           -0.150461 -0.321942 -0.014054       -0.444045  -0.192795   \n",
      "..                ...       ...       ...             ...        ...   \n",
      "494          0.223516 -0.504705  0.232202       -0.487713   0.156862   \n",
      "495         -0.240235 -0.413323  0.675462        0.167316   0.146993   \n",
      "496         -0.595858  0.134964  0.429206        0.079979  -0.946613   \n",
      "497         -1.240314 -0.321942  0.724713        0.735008  -1.629789   \n",
      "498         -2.099588  0.409107  0.330704       -0.487713  -0.946613   \n",
      "\n",
      "     PolicOperBudg  LemasPctPolicOnPatr  LemasGangUnitDeploy  \\\n",
      "0        -0.057091             0.030040             0.143776   \n",
      "1         0.025320            -0.198986             0.113102   \n",
      "2        -0.007387            -0.057710            -0.198240   \n",
      "3        -0.109856             0.007839            -0.061767   \n",
      "4        -0.002898            -0.043949            -0.039705   \n",
      "..             ...                  ...                  ...   \n",
      "494      -0.053733             0.043197             0.195023   \n",
      "495       0.018589             0.089751             0.357622   \n",
      "496      -0.300643             0.941523            -2.628195   \n",
      "497      -1.014240             1.057923            -2.628195   \n",
      "498      -0.657442             0.359528             0.355791   \n",
      "\n",
      "     LemasPctOfficDrugUn  PolicBudgPerPop  \n",
      "0              -0.391447         0.280558  \n",
      "1              -0.391447        -0.087102  \n",
      "2              -0.391447        -0.104269  \n",
      "3              -0.391447         0.025062  \n",
      "4              -0.391447         0.066535  \n",
      "..                   ...              ...  \n",
      "494            -0.391447        -0.038289  \n",
      "495            -0.391447        -0.105793  \n",
      "496             3.395990         1.285279  \n",
      "497             0.524197        -0.227529  \n",
      "498             3.770572        -0.983933  \n",
      "\n",
      "[499 rows x 122 columns]\n",
      "0      0.12\n",
      "1      0.11\n",
      "2      0.12\n",
      "3      0.06\n",
      "4      0.12\n",
      "       ... \n",
      "494    0.09\n",
      "495    0.45\n",
      "496    0.23\n",
      "497    0.19\n",
      "498    0.48\n",
      "Name: ViolentCrimesPerPop, Length: 499, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_train = df.iloc[0:1495,:]\n",
    "df_test = df.iloc[1495:1994,:]\n",
    "df_test.reset_index(drop=True,inplace=True)\n",
    "X = df_train.drop(columns=['ViolentCrimesPerPop'])\n",
    "X_final_test = df_test.drop(columns=['ViolentCrimesPerPop'])\n",
    "y = df_train['ViolentCrimesPerPop']\n",
    "y_final_test = df_test['ViolentCrimesPerPop']\n",
    "print(X)\n",
    "print(y)\n",
    "print(X_final_test)\n",
    "print(y_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha selected, via 5-fold CV is : \n",
      " 0.005\n",
      "The final y predicted over test set with the best selected alpha/lambda is : \n",
      " [ 2.08321122e-01  1.01820827e-01  2.48955039e-01  1.20391703e-01\n",
      "  1.83778189e-01  4.49359672e-02  2.19832677e-01  4.32244969e-01\n",
      "  1.15224914e-01  3.06253296e-01  2.21971720e-01  4.33287714e-01\n",
      "  2.21602238e-01  5.46593394e-01  5.06058237e-01  2.50431321e-01\n",
      "  4.11545262e-01  5.24534790e-01  1.82949423e-01  3.92811910e-01\n",
      "  3.84950650e-02  7.56259852e-02  2.41115661e-01  1.86760179e-01\n",
      "  1.42934597e-02  8.89661447e-03  9.20545536e-02  5.87616998e-02\n",
      "  4.30965308e-01  6.42108874e-01  1.33879254e-01  1.86318545e-01\n",
      "  2.32626762e-01  2.10871446e-01  1.23994907e-01  9.64886859e-02\n",
      "  1.24563119e-02  2.89118938e-01  1.97776919e-01  3.62022310e-01\n",
      "  1.88471066e-01  7.33403225e-01  2.46257841e-01  4.22121318e-01\n",
      "  3.96374512e-01  3.54137681e-01  3.67769119e-01  3.05549894e-01\n",
      "  6.29359653e-01  5.06329363e-01  1.32139425e-01  1.16351080e-01\n",
      "  2.79879661e-01  5.12989862e-02  1.25603865e-01  1.47359099e-01\n",
      "  1.52162762e-01  1.83339851e-01  2.30301584e-01  3.41123988e-01\n",
      "  7.35533882e-02  1.88248878e-01  1.99887182e-01  1.32133052e-01\n",
      "  1.08463235e-01  2.14655569e-01  5.64082571e-02  1.22200752e-01\n",
      "  7.13017406e-01  3.16774558e-01  1.35118259e-01  3.36786205e-01\n",
      "  3.50392395e-01  1.55560902e-01  4.74288453e-01  2.43235653e-01\n",
      "  1.09124390e-01  6.25703954e-02  3.67366176e-01  2.88345747e-01\n",
      "  3.45282453e-01  2.17268144e-01  1.27274101e-01  6.29074522e-02\n",
      "  1.06343969e-01  5.53159834e-01  4.00446902e-02  3.69489208e-01\n",
      "  8.82630402e-02  2.89828608e-01  3.64773337e-01  1.11555547e-01\n",
      "  2.27952192e-01  1.22269641e-01  1.93927412e-01  3.82387719e-01\n",
      "  3.18452211e-01  1.23605157e-01  1.99953236e-03  3.00563911e-01\n",
      "  6.10536637e-01  7.46637500e-02  3.05647449e-01  2.70120373e-01\n",
      "  7.21967374e-02  3.52590147e-02  6.38373125e-01  2.17030870e-01\n",
      "  2.30392203e-01  1.92361693e-01  1.58872970e-01  8.76223791e-02\n",
      "  4.53619957e-01  3.37534549e-01  5.47569358e-02  4.36306398e-01\n",
      "  3.64917398e-02  5.56260673e-01  5.01777199e-02  5.42052179e-02\n",
      "  7.03825417e-02  5.20707018e-02  3.06270315e-01  2.35594957e-02\n",
      "  4.53291368e-01  2.16584350e-01  1.19961054e-01  3.46174481e-03\n",
      "  3.24809024e-01  3.04973147e-01  5.53382143e-01  3.24464509e-01\n",
      "  4.61409593e-02  2.85386875e-01  1.34063476e-01  1.26520872e-01\n",
      "  8.42359573e-02  3.70664288e-01  6.57814872e-01  8.07762529e-02\n",
      "  2.34486679e-02  4.23465779e-01  2.61462516e-01  2.69783783e-01\n",
      "  8.84446100e-02  6.15707761e-01  4.30515526e-01  1.77843253e-02\n",
      "  1.51795392e-01  2.25706021e-01  2.02728176e-01  6.89015172e-02\n",
      "  3.62338184e-01  1.01485122e-01  3.17624513e-01  1.74733283e-01\n",
      "  2.22413288e-01  9.49442210e-03  2.73244437e-01  1.96891439e-01\n",
      "  3.16886772e-01  3.94661800e-03  8.79395315e-02  9.92519859e-02\n",
      "  9.80002168e-02  9.52995980e-02  5.63545939e-01  6.29010756e-01\n",
      "  2.33868753e-01  2.53510019e-01  3.05705625e-01  1.46974065e-01\n",
      "  5.39490127e-03  4.69177133e-02  4.66353345e-01  5.72620876e-01\n",
      "  2.08728934e-01  2.35116850e-02  1.11831500e-01  1.53328107e-01\n",
      "  3.25774739e-02  3.83798998e-01  5.04499788e-01  5.79608100e-01\n",
      "  6.54916752e-02  1.70853382e-01  1.21683136e-01  8.75807843e-02\n",
      "  2.05323643e-01  6.19581998e-01  1.67252465e-01  3.26367691e-01\n",
      "  1.47090392e-02  7.65536299e-02  2.12337496e-01  3.90219868e-01\n",
      "  2.99051764e-01  3.97102384e-01  1.97903342e-01  5.00927037e-02\n",
      "  3.04250586e-01  7.40669633e-02  9.08135731e-02  8.31412982e-01\n",
      "  2.79805887e-01  3.23058328e-01  9.48308289e-02  1.67482862e-01\n",
      "  4.72753138e-01  7.69525252e-02  1.42807319e-02  1.12512866e-01\n",
      "  5.18189596e-01  8.28656807e-02  2.36896418e-01  3.79377369e-01\n",
      "  3.55789525e-01  1.98961038e-01  5.21147347e-02  1.80089929e-01\n",
      "  1.39995464e-01  2.95103052e-01  1.84881726e-01  4.58448895e-01\n",
      "  2.11437788e-01  3.45204368e-01  6.66530120e-01  1.38335830e-01\n",
      "  9.01867188e-02  3.20965736e-01  3.61492867e-03  3.54403104e-01\n",
      "  4.21287714e-01  2.52383851e-01  1.89211656e-01  1.13244654e-01\n",
      "  1.15064879e-01  3.53013506e-01  1.77470492e-01  7.19880466e-02\n",
      "  1.23209378e-01  1.25381024e-01  2.27800692e-01  1.60470862e-01\n",
      "  1.43040170e-01  2.34525765e-02  1.94035473e-01  3.93330829e-01\n",
      "  6.66199913e-02  8.75277619e-02  1.02664243e-02  5.88393882e-02\n",
      "  3.24793722e-01  5.38576529e-02  4.78868814e-01  1.61680093e-01\n",
      "  4.70520875e-01  1.01504229e-01  3.19491833e-01  2.90607328e-01\n",
      "  1.01852669e-01  2.67034803e-01  3.07643027e-02  2.59180662e-02\n",
      "  7.32066595e-01  7.05267111e-02  5.43006521e-02  4.01315731e-02\n",
      "  1.14668043e-01  2.29495771e-01  1.53619098e-01  3.39755619e-02\n",
      "  4.96354163e-01  5.73006403e-02  1.51266417e-01  3.98212967e-01\n",
      "  1.23102758e-01  1.56806962e-01  6.12531013e-01  2.23196048e-01\n",
      "  4.53712936e-01  3.90157056e-02  6.00650638e-01  4.16964358e-01\n",
      "  3.70333181e-01  1.13921757e-01  1.45954048e-01  7.63809006e-02\n",
      "  3.96026278e-01  2.17900477e-01  3.53984025e-02  5.56953876e-02\n",
      "  3.59967578e-01  3.25576578e-01  4.93671951e-01  4.20056165e-01\n",
      "  1.98971988e-02  4.27862745e-01  7.25527953e-02  7.37781707e-02\n",
      "  1.65745275e-01  2.17299100e-01  1.10309125e-01  1.09096076e-01\n",
      "  2.68988904e-01  1.70906230e-01  5.38761124e-01  1.12699635e-01\n",
      "  3.01902914e-01  6.40908401e-02  8.83451767e-02  2.47478127e-01\n",
      "  2.89185903e-02  5.01485022e-01  1.33450836e-01  5.89313840e-01\n",
      "  2.83465200e-01  2.12156345e-01  3.05539950e-01  1.28791010e-01\n",
      "  7.00317796e-01  4.53015871e-02  5.12724788e-01  3.83878619e-02\n",
      "  2.29942870e-01  2.86355713e-01  2.24410811e-01  7.13751017e-01\n",
      "  1.82670524e-01  5.79463651e-02  2.20677897e-01  8.29774913e-02\n",
      "  5.43649604e-02  1.63131883e-01  1.82485030e-01  1.78281054e-01\n",
      "  4.19252650e-01  2.53466437e-02  6.23789363e-02  6.22802381e-02\n",
      "  7.04309526e-01  7.32454325e-01  1.93087840e-01  5.56266599e-01\n",
      "  2.16547490e-01  3.58655836e-01  4.82870374e-01  5.61910117e-01\n",
      "  3.55306553e-01  2.56523865e-02  1.95730847e-01  1.29091618e-01\n",
      "  1.01105502e+00  1.06534054e-01  7.42114810e-01  1.52975353e-01\n",
      "  2.73841029e-01  2.39494157e-01  1.00365984e-01  1.26230668e-01\n",
      "  2.48557414e-01  2.10465465e-01  7.60883364e-02  1.76196436e-01\n",
      "  3.97555068e-01  2.55219909e-01  1.97520523e-01  2.66380195e-01\n",
      "  4.39901883e-02  4.77485471e-03  6.47671203e-01  1.81046739e-01\n",
      "  1.51015292e-01  6.40625755e-02  1.48498448e-01  2.80952398e-01\n",
      "  3.82386946e-02  5.54910606e-01  1.49828196e-01  1.57214575e-01\n",
      "  2.85369961e-01  2.08274135e-01  2.22773177e-01  5.56525214e-01\n",
      "  7.35415416e-01  2.60474095e-01  1.01482042e-01  6.70096065e-02\n",
      "  1.93303641e-01  3.49029534e-01  7.43309685e-02  2.33435994e-01\n",
      "  3.79115747e-01  1.47179837e-01  2.15666295e-01  1.10437966e-01\n",
      "  2.54354931e-01  1.68570403e-01  2.68744237e-01  1.01652648e-01\n",
      "  9.45264468e-02  1.11100296e-01  4.09277991e-02  1.27110436e-01\n",
      "  2.37618644e-02  1.77841072e-01  1.56907191e-01  1.73584424e-01\n",
      "  3.12008111e-01  1.23610463e-01  1.74635736e-01  1.82915701e-01\n",
      "  6.23127606e-01  2.18610318e-01  2.54626245e-01  5.71845386e-01\n",
      "  9.01016054e-02  1.42488439e-01  1.50976507e-01  2.69448489e-01\n",
      "  5.35345425e-02  5.25521667e-01  1.77020401e-01  2.68983880e-01\n",
      "  3.35773609e-01  3.96180026e-01  3.26493341e-01  3.58267786e-01\n",
      "  1.57593738e-01  1.41059047e-01  4.08704633e-01  1.24903641e-01\n",
      "  8.53821864e-02  2.64803647e-01  1.77253310e-01 -7.22675947e-04\n",
      "  1.64853232e-01  1.01832182e-02  5.76530151e-02  6.36197332e-02\n",
      "  5.67061262e-02  9.21967654e-02  1.03610769e-01  2.04184573e-01\n",
      "  1.53467091e-01  3.51913527e-01  2.95064452e-01  2.03582432e-01\n",
      "  3.02711471e-01  1.49810096e-01  1.90244327e-01  3.04872214e-01\n",
      "  1.54487985e-01  1.82011086e-02  3.60774383e-01  8.24775561e-02\n",
      "  1.73607751e-01  1.48193562e-01  1.44672017e-01  5.94469987e-01\n",
      "  5.59898724e-02  3.46125815e-01  4.78122221e-01  2.25816488e-01\n",
      "  1.17385236e-01  1.02980621e-01  3.02440514e-01  3.68583281e-01\n",
      "  5.44586904e-01  6.26973077e-01  5.59243976e-01  3.45917386e-01\n",
      " -1.12826370e-02  4.51299889e-01  6.67372900e-01  2.92783362e-01\n",
      "  2.74563736e-01  2.31311049e-01  6.28011797e-02  4.03910045e-01\n",
      "  1.80904340e-01  7.52356588e-02  1.74598498e-01  6.06921300e-02\n",
      "  2.71429927e-01  1.98221292e-01  9.80216009e-02  3.56641120e-03\n",
      "  3.73064883e-01  4.71839872e-02  3.20844743e-01  2.71797817e-02\n",
      "  3.75756756e-02  6.13540221e-01  1.40433414e-01  4.02947997e-01\n",
      "  3.66596477e-01  1.29169483e-01  4.16667887e-01]\n",
      "The y_test for comparison is : \n",
      " 0      0.12\n",
      "1      0.11\n",
      "2      0.12\n",
      "3      0.06\n",
      "4      0.12\n",
      "       ... \n",
      "494    0.09\n",
      "495    0.45\n",
      "496    0.23\n",
      "497    0.19\n",
      "498    0.48\n",
      "Name: ViolentCrimesPerPop, Length: 499, dtype: float64\n",
      "The corresponding MSE is : \n",
      " 0.017299611815589425\n"
     ]
    }
   ],
   "source": [
    "alpha = np.array([5*(10**(-3)),5*(10**(-2)),5*(10**(-1)),5*(10**(0)),5*(10**(1))])\n",
    "alpha_pointer = np.arange(0,5)\n",
    "alpha_mse_sum = np.zeros(5)\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    i=0\n",
    "    for i in alpha_pointer:\n",
    "        lasso_reg = linear_model.Lasso(alpha=alpha[i],fit_intercept=True,normalize=False) #Already Normalized, Fit Intercept\n",
    "        lasso_fit = lasso_reg.fit(X_train,y_train)\n",
    "        y_predicted = lasso_fit.predict(X_test)\n",
    "        mse_interim = mean_squared_error(y_test,y_predicted)\n",
    "        alpha_mse_sum[i] = alpha_mse_sum[i] + mse_interim #alpha_mse_sum stores mse in indices corresponding to alphas, and \n",
    "                                                          #it keeps summing mse's for each alpha over every single fold, \n",
    "                                                          #final mse obtained by dividing by 5 \n",
    "                \n",
    "final_alpha_mse = alpha_mse_sum/5 #alpha mse were summed, dividing by 5 gives us the average mse for each alpha over 5-folds\n",
    "\n",
    "\n",
    "selected_alpha_index = np.argmin(final_alpha_mse) #returns index with minimal mse, corresponding to index for alpha\n",
    "\n",
    "print('The alpha selected, via 5-fold CV is : \\n',alpha[selected_alpha_index])\n",
    "\n",
    "final_lasso = linear_model.Lasso(alpha=alpha[selected_alpha_index],fit_intercept=True,normalize=False)\n",
    "\n",
    "final_fit = final_lasso.fit(X,y) #fitting on the entire training set\n",
    "\n",
    "y_final_predicted = final_fit.predict(X_final_test)\n",
    "\n",
    "print('The final y predicted over test set with the best selected alpha/lambda is : \\n',y_final_predicted)\n",
    "print('The y_test for comparison is : \\n',y_final_test)\n",
    "\n",
    "final_mse = mean_squared_error(y_final_test,y_final_predicted)\n",
    "\n",
    "print('The corresponding MSE is : \\n',final_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.04729347 -0.00609258  0.          0.\n",
      " -0.         -0.00690765 -0.          0.          0.          0.01346645\n",
      "  0.         -0.          0.         -0.00113926  0.          0.00050004\n",
      " -0.00330813 -0.          0.          0.         -0.         -0.\n",
      "  0.00163309  0.          0.          0.         -0.          0.\n",
      "  0.         -0.          0.          0.         -0.         -0.\n",
      "  0.         -0.          0.02208839  0.          0.          0.\n",
      "  0.         -0.         -0.05374433 -0.         -0.         -0.\n",
      " -0.01079987  0.          0.03472871 -0.         -0.         -0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.         -0.\n",
      "  0.         -0.          0.0314939   0.00341925 -0.          0.01484302\n",
      " -0.00633712 -0.          0.00736572 -0.         -0.          0.\n",
      " -0.          0.          0.          0.         -0.          0.\n",
      "  0.          0.          0.00578951  0.         -0.00250519  0.\n",
      "  0.01387059  0.00585124 -0.         -0.          0.          0.\n",
      " -0.          0.          0.          0.         -0.          0.00076971\n",
      "  0.0039795   0.         -0.00175201 -0.         -0.          0.\n",
      "  0.00027149 -0.         -0.         -0.         -0.          0.\n",
      "  0.         -0.          0.         -0.          0.          0.00487138\n",
      "  0.00065387  0.        ]\n",
      "0.23967264717977774\n"
     ]
    }
   ],
   "source": [
    "coef_header = final_fit.coef_\n",
    "coef_intercept = final_fit.intercept_\n",
    "print(coef_header)\n",
    "print(coef_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['racepctblack', 'racePctWhite', 'agePct12t29', 'pctUrban', 'pctWInvInc', 'pctWPubAsst', 'pctWRetire', 'AsianPerCap', 'MalePctDivorce', 'PctKids2Par', 'PctWorkMom', 'PctIlleg', 'PctPersDenseHous', 'PctHousLess3BR', 'HousVacant', 'PctHousOccup', 'PctVacantBoarded', 'MedRentPctHousInc', 'MedOwnCostPctIncNoMtg', 'NumStreet', 'PctForeignBorn', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'RacialMatchCommPol', 'PctPolicAsian', 'LemasGangUnitDeploy', 'LemasPctOfficDrugUn']\n"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "all_features = X.columns\n",
    "i=0\n",
    "for i in np.arange(0,122):\n",
    "    if coef_header[i] != 0:\n",
    "        feature_list.append(all_features[i])\n",
    "        \n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions and Comparisons\n",
    "\n",
    "With standardization, there isn't much difference in the obtained test MSE, from the non-standardized case. Note in our case the non-standardized dataset was still a normalized one.\n",
    "\n",
    "The lambda/alpha chosen via 5-fold CV for both was the same, 0.005\n",
    "\n",
    "Additionally, the total number of features in standardized version that are preserved are much higher than those in the normalized (non-standardized) version.\n",
    "\n",
    "Thus, looking to interpretability and test MSE, the non-standardized version (normalized, still, in our case) may be preferred, as standardization doesn't improve the test MSE and at the same time makes the model less interpretable by adding more features.\n",
    "\n",
    "NOTE: The target vector in both cases (normalized and standardized) was untouched, and thus the final test MSE's can be compared directly. MSE is the mean of error squared, which for different y's takes different scales. Here y's are same and so test MSE can be compared directly.\n",
    "\n",
    "\n",
    "Thus in conclusion:\n",
    "Choose Normalized Version (not standardized) (not raw either) as it gives same test MSE and we get less features/more interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
