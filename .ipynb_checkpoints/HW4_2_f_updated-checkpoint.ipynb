{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW4\n",
    "2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of the process :\n",
    "\n",
    "SMOTE is considered part of training\n",
    "\n",
    "Thus our method will be thus:\n",
    "\n",
    "We'll use 5 fold CV on the training set (original training set)\n",
    "\n",
    "Next, we'll have generated in each iteration of our 5-fold CV:\n",
    "A CV train and CV test set\n",
    "Since test set (validation) of CV is used to estimate parameters of the final test set, we will keep this test/validation set untouched and won't SMOTE on it as the final test set obviously won't either be SMOTE'd (assumed)\n",
    "\n",
    "The reason for this is simple : We assume that since train, validation and test sets are large enough, when we split train into train and validation, the validation set is a decent representation of the test set in terms of containing approximately the same ratio of classes as the test set\n",
    "\n",
    "Thus SMOTE'ing the validation set and then obtaining prediction, test error estimates, obviously doesn't make sense\n",
    "\n",
    "THUS, Validation set WILL NOT be SMOTE'd\n",
    "      Train set in a CV iteration, in each CV iteration, will be SMOTE'd\n",
    "      Test set obviously assumed to not have been SMOTE'd\n",
    "\n",
    "The model will be fit on this SMOTE'd train set in each CV iteration (total 5) post which the test errors estimated via the un-SMOTE'd validation set, and then the model finally predicting the, again, un-SMOTE'd final test set.\n",
    "\n",
    "This procedure will be followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weka.core.jvm:JVM already running, call jvm.stop() first\n",
      "INFO:weka.core.jvm:JVM already running, call jvm.stop() first\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weka.core.jvm as jvm\n",
    "from weka.classifiers import Classifier\n",
    "from weka.core.converters import Loader, Saver\n",
    "from weka.classifiers import Classifier, Evaluation\n",
    "from weka.core.classes import Random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from weka.filters import Filter\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from weka.core.dataset import create_instances_from_lists\n",
    "from weka.core.dataset import create_instances_from_matrices\n",
    "jvm.start()\n",
    "jvm.start(packages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aa_000    ab_000        ac_000      ad_000  ae_000  af_000  ag_000  \\\n",
      "0       76698  0.000000  2.130706e+09  280.000000     0.0     0.0     0.0   \n",
      "1       33058  0.645959  0.000000e+00  638.509566     0.0     0.0     0.0   \n",
      "2       41040  0.644207  2.280000e+02  100.000000     0.0     0.0     0.0   \n",
      "3          12  0.000000  7.000000e+01   66.000000     0.0    10.0     0.0   \n",
      "4       60874  0.035666  1.368000e+03  458.000000     0.0     0.0     0.0   \n",
      "...       ...       ...           ...         ...     ...     ...     ...   \n",
      "59995  153002  0.355823  6.640000e+02  186.000000     0.0     0.0     0.0   \n",
      "59996    2286  0.000000  2.130707e+09  224.000000     0.0     0.0     0.0   \n",
      "59997     112  0.000000  2.130706e+09   18.000000     0.0     0.0     0.0   \n",
      "59998   80292  0.117141  2.130706e+09  494.000000     0.0     0.0     0.0   \n",
      "59999   40222  0.001512  6.980000e+02  628.000000     0.0     0.0     0.0   \n",
      "\n",
      "       ag_001  ag_002  ag_003  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
      "0         0.0     0.0     0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
      "1         0.0     0.0     0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
      "2         0.0     0.0     0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
      "3         0.0     0.0   318.0  ...      240.0      46.0       58.0       44.0   \n",
      "4         0.0     0.0     0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
      "...       ...     ...     ...  ...        ...       ...        ...        ...   \n",
      "59995     0.0     0.0  2564.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
      "59996     0.0     0.0     0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
      "59997     0.0     0.0     0.0  ...      792.0     386.0      452.0      144.0   \n",
      "59998     0.0     0.0     0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
      "59999     0.0     0.0     0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
      "0       339156.0  157956.0   73224.0       0.0     0.0     0.0  \n",
      "1       133654.0   81140.0   97576.0    1500.0     0.0     0.0  \n",
      "2       320746.0  158022.0   95128.0     514.0     0.0     0.0  \n",
      "3           10.0       0.0       0.0       0.0     4.0    32.0  \n",
      "4       286954.0  311560.0  433954.0    1218.0     0.0     0.0  \n",
      "...          ...       ...       ...       ...     ...     ...  \n",
      "59995  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
      "59996      136.0       0.0       0.0       0.0     0.0     0.0  \n",
      "59997      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
      "59998   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
      "59999   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
      "\n",
      "[60000 rows x 170 columns]\n",
      "       aa_000    ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
      "0          60  0.000000  2.000000e+01    12.0     0.0     0.0     0.0     0.0   \n",
      "1          82  0.000000  6.800000e+01    40.0     0.0     0.0     0.0     0.0   \n",
      "2       66002  2.000000  2.120000e+02   112.0     0.0     0.0     0.0     0.0   \n",
      "3       59816  0.638151  1.010000e+03   936.0     0.0     0.0     0.0     0.0   \n",
      "4        1814  0.108426  1.560000e+02   140.0     0.0     0.0     0.0     0.0   \n",
      "...       ...       ...           ...     ...     ...     ...     ...     ...   \n",
      "15995   81852  0.709256  2.130706e+09   892.0     0.0     0.0     0.0     0.0   \n",
      "15996      18  0.000000  5.200000e+01    46.0     8.0    26.0     0.0     0.0   \n",
      "15997   79636  0.063588  1.670000e+03  1518.0     0.0     0.0     0.0     0.0   \n",
      "15998     110  0.000000  3.600000e+01    32.0     0.0     0.0     0.0     0.0   \n",
      "15999       8  0.000000  6.000000e+00     4.0     2.0     2.0     0.0     0.0   \n",
      "\n",
      "       ag_002    ag_003  ...    ee_002    ee_003    ee_004    ee_005  \\\n",
      "0         0.0    2682.0  ...    1098.0     138.0     412.0     654.0   \n",
      "1         0.0       0.0  ...    1068.0     276.0    1620.0     116.0   \n",
      "2         0.0  199486.0  ...  495076.0  380368.0  440134.0  269556.0   \n",
      "3         0.0       0.0  ...  540820.0  243270.0  483302.0  485332.0   \n",
      "4         0.0       0.0  ...    7646.0    4144.0   18466.0   49782.0   \n",
      "...       ...       ...  ...       ...       ...       ...       ...   \n",
      "15995     0.0       0.0  ...  632658.0  273242.0  510354.0  373918.0   \n",
      "15996     0.0       0.0  ...     266.0      44.0      46.0      14.0   \n",
      "15997     0.0       0.0  ...  806832.0  449962.0  778826.0  581558.0   \n",
      "15998     0.0       0.0  ...     588.0     210.0     180.0     544.0   \n",
      "15999     0.0       0.0  ...      46.0      10.0      48.0      14.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008   ee_009  ef_000  eg_000  \n",
      "0           78.0      88.0       0.0      0.0     0.0     0.0  \n",
      "1           86.0     462.0       0.0      0.0     0.0     0.0  \n",
      "2      1315022.0  153680.0     516.0      0.0     0.0     0.0  \n",
      "3       431376.0  210074.0  281662.0   3232.0     0.0     0.0  \n",
      "4         3176.0     482.0      76.0      0.0     0.0     0.0  \n",
      "...          ...       ...       ...      ...     ...     ...  \n",
      "15995   349840.0  317840.0  960024.0  25566.0     0.0     0.0  \n",
      "15996        2.0       0.0       0.0      0.0     0.0     0.0  \n",
      "15997   375498.0  222866.0  358934.0  19548.0     0.0     0.0  \n",
      "15998     1004.0    1338.0      74.0      0.0     0.0     0.0  \n",
      "15999       42.0      46.0       0.0      0.0     0.0     0.0  \n",
      "\n",
      "[16000 rows x 170 columns]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "59995    0\n",
      "59996    0\n",
      "59997    0\n",
      "59998    0\n",
      "59999    0\n",
      "Name: class, Length: 60000, dtype: int64\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "15995    0\n",
      "15996    0\n",
      "15997    0\n",
      "15998    0\n",
      "15999    0\n",
      "Name: class, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('aps_train.csv',index_col=0)\n",
    "df_test = pd.read_csv('aps_test.csv',index_col=0)\n",
    "X_train = df_train.drop(columns=['class'])\n",
    "X_test = df_test.drop(columns=['class'])\n",
    "y_train = df_train['class']\n",
    "y_test = df_test['class']\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error vector for CV (validation error) is, for all CV iterations : \n",
      " [2.19166667 1.575      1.66666667 1.275      2.375     ]\n",
      "The estimated test error is : \n",
      " 1.8166666666666669\n"
     ]
    }
   ],
   "source": [
    "# Performing Cross Validation for test error estimation\n",
    "\n",
    "kf = KFold(n_splits=5) # We will do 5 fold CV\n",
    "test_error_cv_array = np.zeros(5)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for train_cv_index, test_cv_index in kf.split(X_train):\n",
    "    X_train_cv, X_test_cv = X_train.iloc[train_cv_index,:], X_train.iloc[test_cv_index,:]\n",
    "    y_train_cv, y_test_cv = y_train[train_cv_index], y_train[test_cv_index]\n",
    "    count = count + 1\n",
    "    # SMOTE will be performed on X_train_cv and y_train_cv\n",
    "    \n",
    "    oversample = SMOTE()\n",
    "    X_train_cv_sm, y_train_cv_sm = oversample.fit_resample(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # X_train_cv_sm and y_train_cv_sm contain required SMOTE'd data. We won't perform random undersampling in a pipeline\n",
    "    # format due to runtime constraints\n",
    "    \n",
    "    # X_train_cv_sm & y_train_cv_sm\n",
    "    \n",
    "    dataset = pd.concat([X_train_cv_sm,y_train_cv_sm],axis=1)\n",
    "    \n",
    "    # dataset contains the new data obtained after SMOTE\n",
    "    # note that SMOTE retains column headers of our dataframe\n",
    "    \n",
    "    dataset_array = dataset.to_numpy()\n",
    "    \n",
    "    # this dataset_array now has dataframe as an array, so that weka can read it as a list\n",
    "    \n",
    "    data_interim = create_instances_from_lists(dataset_array)\n",
    "    \n",
    "    discretize_class = Filter(classname = 'weka.filters.unsupervised.attribute.NumericToNominal', options = ['-R', 'last'])\n",
    "    \n",
    "    discretize_class.inputformat(data_interim)\n",
    "    \n",
    "    data = discretize_class.filter(data_interim)\n",
    "    \n",
    "    # this is data read by weka, contains classes at the end\n",
    "    \n",
    "    \n",
    "    \n",
    "    # cls on smote as this is our fit, fit on SMOTE\n",
    "    \n",
    "    cls_on_smote = Classifier(classname=\"weka.classifiers.trees.LMT\")\n",
    "    \n",
    "    data.class_is_last()\n",
    "    \n",
    "    cls_on_smote.build_classifier(data)\n",
    "    \n",
    "    # cls_on_smote has the classification model now, trained on SMOTE'd CV Train\n",
    "    \n",
    "    validate_dataset_array = pd.concat([X_test_cv, y_test_cv], axis=1).to_numpy()  \n",
    "    \n",
    "    # validate_dataset_array is numpy of X_test_cv\n",
    "    \n",
    "    validate_dataset_interim = create_instances_from_lists(validate_dataset_array)\n",
    "    \n",
    "    discretize_class.inputformat(validate_dataset_interim)\n",
    "    \n",
    "    validate_dataset = discretize_class.filter(validate_dataset_interim)\n",
    "    \n",
    "    validate_dataset.class_is_last()\n",
    "    \n",
    "    # validate_dataset contains the instances with only feature data, to predict on\n",
    "    \n",
    "    y_test_cv_predicted = np.zeros(y_test_cv.shape[0])\n",
    "    \n",
    "    for index,inst in enumerate(validate_dataset):\n",
    "        y_test_cv_predicted[index] = cls_on_smote.classify_instance(inst) \n",
    "        \n",
    "    \n",
    "    # y_test_cv_predicted contains predicted y values in a numpy array\n",
    "    \n",
    "    mis = 0\n",
    "    for i in np.arange(0,y_test_cv.shape[0]):\n",
    "        if y_test_cv_predicted[i] != y_test_cv.iloc[i]:\n",
    "            mis = mis + 1\n",
    "            \n",
    "\n",
    "    \n",
    "    \n",
    "    error_test = (mis/(y_test_cv.shape[0]))*100\n",
    "    \n",
    "    test_error_cv_array[count-1] = error_test   # in percentage\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print('The test error vector for CV (validation error) is, for all CV iterations : \\n',test_error_cv_array)\n",
    "\n",
    "estimated_test_error = np.mean(test_error_cv_array)\n",
    "\n",
    "print('The estimated test error is : \\n', estimated_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above the cross validated test error estimate in percentage is 1.8 % approximately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
