{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW4\n",
    "2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a few methods have been described for Random Forests to deal with class imbalance\n",
    "Downsampling, Upsampling, SMOTE, UpDown sampling, all are valid\n",
    "Another technique used often is thus :\n",
    "Since Random Forests technique has a tendency of being biased towards the majority class, the penalty whenever misclassification of the minority class happens can be increased. This, thus helps RF to be more 'careful' before classifying to the majority or misclassifying the minority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       class  aa_000    ab_000        ac_000      ad_000  ae_000  af_000  \\\n",
      "0          0   76698  0.000000  2.130706e+09  280.000000     0.0     0.0   \n",
      "1          0   33058  0.645959  0.000000e+00  638.509566     0.0     0.0   \n",
      "2          0   41040  0.644207  2.280000e+02  100.000000     0.0     0.0   \n",
      "3          0      12  0.000000  7.000000e+01   66.000000     0.0    10.0   \n",
      "4          0   60874  0.035666  1.368000e+03  458.000000     0.0     0.0   \n",
      "...      ...     ...       ...           ...         ...     ...     ...   \n",
      "59995      0  153002  0.355823  6.640000e+02  186.000000     0.0     0.0   \n",
      "59996      0    2286  0.000000  2.130707e+09  224.000000     0.0     0.0   \n",
      "59997      0     112  0.000000  2.130706e+09   18.000000     0.0     0.0   \n",
      "59998      0   80292  0.117141  2.130706e+09  494.000000     0.0     0.0   \n",
      "59999      0   40222  0.001512  6.980000e+02  628.000000     0.0     0.0   \n",
      "\n",
      "       ag_000  ag_001  ag_002  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
      "0         0.0     0.0     0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
      "1         0.0     0.0     0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
      "2         0.0     0.0     0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
      "3         0.0     0.0     0.0  ...      240.0      46.0       58.0       44.0   \n",
      "4         0.0     0.0     0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
      "...       ...     ...     ...  ...        ...       ...        ...        ...   \n",
      "59995     0.0     0.0     0.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
      "59996     0.0     0.0     0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
      "59997     0.0     0.0     0.0  ...      792.0     386.0      452.0      144.0   \n",
      "59998     0.0     0.0     0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
      "59999     0.0     0.0     0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
      "0       339156.0  157956.0   73224.0       0.0     0.0     0.0  \n",
      "1       133654.0   81140.0   97576.0    1500.0     0.0     0.0  \n",
      "2       320746.0  158022.0   95128.0     514.0     0.0     0.0  \n",
      "3           10.0       0.0       0.0       0.0     4.0    32.0  \n",
      "4       286954.0  311560.0  433954.0    1218.0     0.0     0.0  \n",
      "...          ...       ...       ...       ...     ...     ...  \n",
      "59995  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
      "59996      136.0       0.0       0.0       0.0     0.0     0.0  \n",
      "59997      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
      "59998   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
      "59999   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
      "\n",
      "[60000 rows x 171 columns]\n",
      "       class  aa_000    ab_000        ac_000  ad_000  ae_000  af_000  ag_000  \\\n",
      "0          0      60  0.000000  2.000000e+01    12.0     0.0     0.0     0.0   \n",
      "1          0      82  0.000000  6.800000e+01    40.0     0.0     0.0     0.0   \n",
      "2          0   66002  2.000000  2.120000e+02   112.0     0.0     0.0     0.0   \n",
      "3          0   59816  0.638151  1.010000e+03   936.0     0.0     0.0     0.0   \n",
      "4          0    1814  0.108426  1.560000e+02   140.0     0.0     0.0     0.0   \n",
      "...      ...     ...       ...           ...     ...     ...     ...     ...   \n",
      "15995      0   81852  0.709256  2.130706e+09   892.0     0.0     0.0     0.0   \n",
      "15996      0      18  0.000000  5.200000e+01    46.0     8.0    26.0     0.0   \n",
      "15997      0   79636  0.063588  1.670000e+03  1518.0     0.0     0.0     0.0   \n",
      "15998      0     110  0.000000  3.600000e+01    32.0     0.0     0.0     0.0   \n",
      "15999      0       8  0.000000  6.000000e+00     4.0     2.0     2.0     0.0   \n",
      "\n",
      "       ag_001  ag_002  ...    ee_002    ee_003    ee_004    ee_005     ee_006  \\\n",
      "0         0.0     0.0  ...    1098.0     138.0     412.0     654.0       78.0   \n",
      "1         0.0     0.0  ...    1068.0     276.0    1620.0     116.0       86.0   \n",
      "2         0.0     0.0  ...  495076.0  380368.0  440134.0  269556.0  1315022.0   \n",
      "3         0.0     0.0  ...  540820.0  243270.0  483302.0  485332.0   431376.0   \n",
      "4         0.0     0.0  ...    7646.0    4144.0   18466.0   49782.0     3176.0   \n",
      "...       ...     ...  ...       ...       ...       ...       ...        ...   \n",
      "15995     0.0     0.0  ...  632658.0  273242.0  510354.0  373918.0   349840.0   \n",
      "15996     0.0     0.0  ...     266.0      44.0      46.0      14.0        2.0   \n",
      "15997     0.0     0.0  ...  806832.0  449962.0  778826.0  581558.0   375498.0   \n",
      "15998     0.0     0.0  ...     588.0     210.0     180.0     544.0     1004.0   \n",
      "15999     0.0     0.0  ...      46.0      10.0      48.0      14.0       42.0   \n",
      "\n",
      "         ee_007    ee_008   ee_009  ef_000  eg_000  \n",
      "0          88.0       0.0      0.0     0.0     0.0  \n",
      "1         462.0       0.0      0.0     0.0     0.0  \n",
      "2      153680.0     516.0      0.0     0.0     0.0  \n",
      "3      210074.0  281662.0   3232.0     0.0     0.0  \n",
      "4         482.0      76.0      0.0     0.0     0.0  \n",
      "...         ...       ...      ...     ...     ...  \n",
      "15995  317840.0  960024.0  25566.0     0.0     0.0  \n",
      "15996       0.0       0.0      0.0     0.0     0.0  \n",
      "15997  222866.0  358934.0  19548.0     0.0     0.0  \n",
      "15998    1338.0      74.0      0.0     0.0     0.0  \n",
      "15999      46.0       0.0      0.0     0.0     0.0  \n",
      "\n",
      "[16000 rows x 171 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_train = pd.read_csv('aps_train.csv',index_col=0)\n",
    "df_test = pd.read_csv('aps_test.csv',index_col=0)\n",
    "\n",
    "print(df_train)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aa_000    ab_000        ac_000      ad_000  ae_000  af_000  ag_000  \\\n",
      "0       76698  0.000000  2.130706e+09  280.000000     0.0     0.0     0.0   \n",
      "1       33058  0.645959  0.000000e+00  638.509566     0.0     0.0     0.0   \n",
      "2       41040  0.644207  2.280000e+02  100.000000     0.0     0.0     0.0   \n",
      "3          12  0.000000  7.000000e+01   66.000000     0.0    10.0     0.0   \n",
      "4       60874  0.035666  1.368000e+03  458.000000     0.0     0.0     0.0   \n",
      "...       ...       ...           ...         ...     ...     ...     ...   \n",
      "59995  153002  0.355823  6.640000e+02  186.000000     0.0     0.0     0.0   \n",
      "59996    2286  0.000000  2.130707e+09  224.000000     0.0     0.0     0.0   \n",
      "59997     112  0.000000  2.130706e+09   18.000000     0.0     0.0     0.0   \n",
      "59998   80292  0.117141  2.130706e+09  494.000000     0.0     0.0     0.0   \n",
      "59999   40222  0.001512  6.980000e+02  628.000000     0.0     0.0     0.0   \n",
      "\n",
      "       ag_001  ag_002  ag_003  ...     ee_002    ee_003     ee_004     ee_005  \\\n",
      "0         0.0     0.0     0.0  ...  1240520.0  493384.0   721044.0   469792.0   \n",
      "1         0.0     0.0     0.0  ...   421400.0  178064.0   293306.0   245416.0   \n",
      "2         0.0     0.0     0.0  ...   277378.0  159812.0   423992.0   409564.0   \n",
      "3         0.0     0.0   318.0  ...      240.0      46.0       58.0       44.0   \n",
      "4         0.0     0.0     0.0  ...   622012.0  229790.0   405298.0   347188.0   \n",
      "...       ...     ...     ...  ...        ...       ...        ...        ...   \n",
      "59995     0.0     0.0  2564.0  ...   998500.0  566884.0  1290398.0  1218244.0   \n",
      "59996     0.0     0.0     0.0  ...    10578.0    6760.0    21126.0    68424.0   \n",
      "59997     0.0     0.0     0.0  ...      792.0     386.0      452.0      144.0   \n",
      "59998     0.0     0.0     0.0  ...   699352.0  222654.0   347378.0   225724.0   \n",
      "59999     0.0     0.0     0.0  ...   440066.0  183200.0   344546.0   254068.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
      "0       339156.0  157956.0   73224.0       0.0     0.0     0.0  \n",
      "1       133654.0   81140.0   97576.0    1500.0     0.0     0.0  \n",
      "2       320746.0  158022.0   95128.0     514.0     0.0     0.0  \n",
      "3           10.0       0.0       0.0       0.0     4.0    32.0  \n",
      "4       286954.0  311560.0  433954.0    1218.0     0.0     0.0  \n",
      "...          ...       ...       ...       ...     ...     ...  \n",
      "59995  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
      "59996      136.0       0.0       0.0       0.0     0.0     0.0  \n",
      "59997      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
      "59998   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
      "59999   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
      "\n",
      "[60000 rows x 170 columns]\n",
      "       aa_000    ab_000        ac_000  ad_000  ae_000  af_000  ag_000  ag_001  \\\n",
      "0          60  0.000000  2.000000e+01    12.0     0.0     0.0     0.0     0.0   \n",
      "1          82  0.000000  6.800000e+01    40.0     0.0     0.0     0.0     0.0   \n",
      "2       66002  2.000000  2.120000e+02   112.0     0.0     0.0     0.0     0.0   \n",
      "3       59816  0.638151  1.010000e+03   936.0     0.0     0.0     0.0     0.0   \n",
      "4        1814  0.108426  1.560000e+02   140.0     0.0     0.0     0.0     0.0   \n",
      "...       ...       ...           ...     ...     ...     ...     ...     ...   \n",
      "15995   81852  0.709256  2.130706e+09   892.0     0.0     0.0     0.0     0.0   \n",
      "15996      18  0.000000  5.200000e+01    46.0     8.0    26.0     0.0     0.0   \n",
      "15997   79636  0.063588  1.670000e+03  1518.0     0.0     0.0     0.0     0.0   \n",
      "15998     110  0.000000  3.600000e+01    32.0     0.0     0.0     0.0     0.0   \n",
      "15999       8  0.000000  6.000000e+00     4.0     2.0     2.0     0.0     0.0   \n",
      "\n",
      "       ag_002    ag_003  ...    ee_002    ee_003    ee_004    ee_005  \\\n",
      "0         0.0    2682.0  ...    1098.0     138.0     412.0     654.0   \n",
      "1         0.0       0.0  ...    1068.0     276.0    1620.0     116.0   \n",
      "2         0.0  199486.0  ...  495076.0  380368.0  440134.0  269556.0   \n",
      "3         0.0       0.0  ...  540820.0  243270.0  483302.0  485332.0   \n",
      "4         0.0       0.0  ...    7646.0    4144.0   18466.0   49782.0   \n",
      "...       ...       ...  ...       ...       ...       ...       ...   \n",
      "15995     0.0       0.0  ...  632658.0  273242.0  510354.0  373918.0   \n",
      "15996     0.0       0.0  ...     266.0      44.0      46.0      14.0   \n",
      "15997     0.0       0.0  ...  806832.0  449962.0  778826.0  581558.0   \n",
      "15998     0.0       0.0  ...     588.0     210.0     180.0     544.0   \n",
      "15999     0.0       0.0  ...      46.0      10.0      48.0      14.0   \n",
      "\n",
      "          ee_006    ee_007    ee_008   ee_009  ef_000  eg_000  \n",
      "0           78.0      88.0       0.0      0.0     0.0     0.0  \n",
      "1           86.0     462.0       0.0      0.0     0.0     0.0  \n",
      "2      1315022.0  153680.0     516.0      0.0     0.0     0.0  \n",
      "3       431376.0  210074.0  281662.0   3232.0     0.0     0.0  \n",
      "4         3176.0     482.0      76.0      0.0     0.0     0.0  \n",
      "...          ...       ...       ...      ...     ...     ...  \n",
      "15995   349840.0  317840.0  960024.0  25566.0     0.0     0.0  \n",
      "15996        2.0       0.0       0.0      0.0     0.0     0.0  \n",
      "15997   375498.0  222866.0  358934.0  19548.0     0.0     0.0  \n",
      "15998     1004.0    1338.0      74.0      0.0     0.0     0.0  \n",
      "15999       42.0      46.0       0.0      0.0     0.0     0.0  \n",
      "\n",
      "[16000 rows x 170 columns]\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns=['class'])\n",
    "X_test = df_test.drop(columns=['class'])\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "59995    0\n",
      "59996    0\n",
      "59997    0\n",
      "59998    0\n",
      "59999    0\n",
      "Name: class, Length: 60000, dtype: int64\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "15995    0\n",
      "15996    0\n",
      "15997    0\n",
      "15998    0\n",
      "15999    0\n",
      "Name: class, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['class']\n",
    "y_test = df_test['class']\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "59995    0\n",
      "59996    0\n",
      "59997    0\n",
      "59998    0\n",
      "59999    0\n",
      "Name: class, Length: 60000, dtype: int64\n",
      "[0 0 0 ... 0 0 0]\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "15995    0\n",
      "15996    0\n",
      "15997    0\n",
      "15998    0\n",
      "15999    0\n",
      "Name: class, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_weight = dict({0:0.002, 1:100000})\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100,max_features='sqrt',bootstrap=True,oob_score=True,class_weight=class_weight) \n",
    "# draws all sample from train, class weight assigns penalty weights\n",
    "forest_fit = forest.fit(X_train,y_train)\n",
    "y_train_predicted = forest_fit.predict(X_train)\n",
    "y_test_predicted = forest_fit.predict(X_test)\n",
    "\n",
    "print(y_train_predicted)\n",
    "print(y_train)\n",
    "\n",
    "print(y_test_predicted)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error is : \n",
      " 3.368749999999998 %\n",
      "oob error is : \n",
      " 3.4533333333333305 %\n"
     ]
    }
   ],
   "source": [
    "test_error = (1-forest_fit.score(X_test, y_test))*100\n",
    "oob_error = (1-forest_fit.oob_score_)*100\n",
    "\n",
    "print('Test error is : \\n',test_error,'%')\n",
    "print('oob error is : \\n',oob_error,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57151  1849]\n",
      " [    0  1000]]\n",
      "[[15137   488]\n",
      " [   51   324]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_train = confusion_matrix(y_train,y_train_predicted)\n",
    "conf_test = confusion_matrix(y_test,y_test_predicted)\n",
    "\n",
    "print(conf_train)\n",
    "print(conf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Confusion is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0        57151         1849\n",
      "Actually 1            0         1000\n",
      "Test Confusion is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0        15137          488\n",
      "Actually 1           51          324\n"
     ]
    }
   ],
   "source": [
    "index_row = ['Actually 0','Actually 1']\n",
    "header_col = ['Predicted 0','Predicted 1']\n",
    "\n",
    "train_conf = pd.DataFrame(conf_train,index=index_row,columns=header_col)\n",
    "test_conf = pd.DataFrame(conf_test,index=index_row,columns=header_col)\n",
    "\n",
    "print('Training Confusion is : \\n',train_conf)\n",
    "print('Test Confusion is : \\n',test_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          TPR       FPR\n",
      "0           0         0\n",
      "1    0.205333  0.002112\n",
      "2       0.264  0.002944\n",
      "3       0.312    0.0048\n",
      "4       0.352  0.006016\n",
      "..        ...       ...\n",
      "96   0.962667  0.106816\n",
      "97      0.968  0.117952\n",
      "98      0.968  0.137856\n",
      "99   0.978667  0.171904\n",
      "100         1         1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "threshold_range = np.arange(0,1.01,0.01)\n",
    "pointer = np.arange(0,np.size(threshold_range))\n",
    "y_test_prob = forest_fit.predict_proba(X_test)\n",
    "y_test_prob_0 = y_test_prob[:,0]\n",
    "ROC_df = pd.DataFrame(index=np.arange(0,np.size(threshold_range)),columns=['TPR','FPR'])\n",
    "\n",
    "i=0\n",
    "for i in pointer:\n",
    "    y_test_predicted_new = (y_test_prob_0 <= threshold_range[i]).astype(int)\n",
    "    conf_test_new = confusion_matrix(y_test,y_test_predicted_new)\n",
    "    TPR = conf_test_new[1][1]/(conf_test_new[1][1]+conf_test_new[1][0])\n",
    "    FPR = conf_test_new[0][1]/(conf_test_new[0][1]+conf_test_new[0][0])\n",
    "    ROC_df.iloc[i,0]=TPR\n",
    "    ROC_df.iloc[i,1]=FPR    \n",
    "    \n",
    "print(ROC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x169df0010c8>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(data=ROC_df,x='FPR',y='TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TPR         FPR\n",
      "0        0           0\n",
      "1    0.323  0.00184746\n",
      "2    0.454  0.00310169\n",
      "3    0.526   0.0049661\n",
      "4    0.564  0.00613559\n",
      "..     ...         ...\n",
      "96       1    0.106288\n",
      "97       1    0.118898\n",
      "98       1    0.138407\n",
      "99       1    0.169763\n",
      "100      1           1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train_prob = forest_fit.predict_proba(X_train)\n",
    "y_train_prob_0 = y_train_prob[:,0]\n",
    "ROC_train_df = pd.DataFrame(index=np.arange(0,np.size(threshold_range)),columns=['TPR','FPR'])\n",
    "\n",
    "i=0\n",
    "for i in pointer:\n",
    "    y_train_predicted_new = (y_train_prob_0 <= threshold_range[i]).astype(int)\n",
    "    conf_train_new = confusion_matrix(y_train,y_train_predicted_new)\n",
    "    TPR = conf_train_new[1][1]/(conf_train_new[1][1]+conf_train_new[1][0])\n",
    "    FPR = conf_train_new[0][1]/(conf_train_new[0][1]+conf_train_new[0][0])\n",
    "    ROC_train_df.iloc[i,0]=TPR\n",
    "    ROC_train_df.iloc[i,1]=FPR    \n",
    "    \n",
    "print(ROC_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x169df22bf08>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAYAAACFYaNMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAatUlEQVR4nO3df5ClVX3n8ff33u7L9IyDtMNIZRkQXIHKLGFj6EKz1CZaqIVEoSwoF3YJathhDYupWi1LUq6Fi5vdFTaxYgWDkKgMWxF/FcmUZdBdg2UWRWkXxDDuWLNgQosLw9CyMPTMnb73u3/cO01P09PTMP3cc6ef96uqq+/zY25/H7r7w+nznHOeyEwkSYPXKF2AJNWVASxJhRjAklSIASxJhRjAklTISOkCXqzzzz8/77rrrtJlSNKLEYvtPOpawE8++WTpEiRpRRx1ASxJq4UBLEmFGMCSVIgBLEmFGMCSVIgBLEmFGMCSVIgBLEmFGMCSVIgBLEmFGMCSVIgBLEmFVLYaWkR8Bngb8ERmnrnI8QD+GLgAeA54d2b+r6rqWY69e2dpM8v8x+R1us+/7nYP7EsSaDaCbjfZ300aASONBvs7XRoNyAyaAZ2EzKQ10mR8bJTpmf20Zzu0RppsWNcCYPee9kH7Go2Y9zVzyeOSqjGI370ql6P8HPAnwNZDHH8rcFr/43XAn/Y/F7F37ywz3Vm688J33+zz6bu/k2Qm7dkuM+0Oa0YbRAS7n23z2Xse4eo3voaZdofP3vMI7/pnp3Lbd3qfP/SVB5manuEtm1/J7513Ou/9bz9ganqGTeNjbP2dc9g322XL1sm5fbdeMcEZJ6yn0Q/3HY8/c8jjkqoxqN+9yrogMvPbwFNLnHIRsDV77gWOi4hfqqqepczOdtk90+a5fV32tp//6HSY+9g/m8x24GfTe3lqz36ajSY/m97LB7/8IBeffRLTe/bPvf7QV57/PDU9A8DFZ580F74AU9Mz/P3u5+a+wQf2bdk6ye49baDXMl7quKRqDOp3r+SC7CcCj87bnurv+/nCEyPiKuAqgJNPPnnFC3ni2X3Mzm/69s3fc+B/emtbzbntta0mU9MzHDc2CjD3ev7nAxZuH3ivhfumpmdoz3YAaM92ljwuqRqD+t0reRNusXb8C1MQyMxbMnMiMyc2bty44oXs73QZacQLPprx/Ec3oZvwXLvDc+3O3OtN42P8Ymb/Qa/nfz5g4TY8/+/n2zQ+RmukF/KtkeaSxyVVY1C/eyUDeAo4ad72JuCxEoWMNII1rQZrj2mwpvX8R7PJ3MfoSDDShBPH1/CKdaN0uh1OHF/DjZecxVd+8Cjj60bnXn/84uc/H/gmfuUHj3Lz5WfPbW8aH+NVG9Zy6xUTB+279YqJuZtzG9a1ljwuqRqD+t2LzEUbnSvz5hGnAF89xCiI3wKuoTcK4nXAJzPznMO958TERE5OTq5onU8+s5ennmtz/MtajDR5SaMgmgHNuVEQQSaOgpCOYiv8u7foP6xyGNrngTcAx0fEFHAdMAqQmTcDX6MXvjvpDUN7T1W1HE4CrZEGz+7rEASdTEYawdpWg1esW7OiX2vj+mOWte+ARiOWPC6pGoP43assgDPzssMcT+DfVvX1l6vbTTrdZN/+Ds1Gk0Yk3YR9+2cZbfinvqTqHHWPpV9pu/e0aXe67N3f5ak9+1jbavJcu8Mr1o0Sa/1TX1J1aj8VuT3b4enn9r9g+EXS67uVpKrUPoAjgiefbfOpu3fS7t9xa3e6fOrunTQatf/PI6lCte+CiEjG143ynnNP5YNffnBu2uGnf/tsh3tJqlTtA7jThU/dvZP3nHsqt//OOXQyefLZtsO9JFWu9gE82ogXtH5vvOSsxQftSdIKqn0ARwRrW00+dtGZcyMg1raa9FbLlKTq1P4uU2Y6AkJSEbUP4E6y6AiIjvkrqWK174JoBgctnL5pfIyPX3wWTXsgJFWs9gHcSbjtO4/wkbdt5rixUX4xs5/bvvMIH73wBesHSdKKqn0AR+SiLWDvwUmqWu0DuNtdvAV83dv/SenSJK1ytQ/gNaONRccBr2nV/v6kpIrVOoC73d5TjhcdB+xUDEkVq3Uz78k9+/jZL/by0W3bDxqG9tFt25lp++BLSdWqdQt47/4Ou/e02fXsPv7N7T+Y2++DLyUNQq1bwI2IFzw8c9P4GJ++3JXQJFWv1i3gAwvxfPae3iiIDetavGJdi2PXjLgSmqTK1TqAR0Z6C/Fcds6rWNtq8szeWUabwcvX1vo/i6QBqXUXxKFGOjgCQtIg1DqAZ9odR0BIKqbWf2u3RpqOgJBUTK1bwONjo9x8+dkHjYC4+fKzGR8bLVyZpDqodQt4emY/n/zmTw5aB+KT3/wJf/COs9i4/pjS5Ula5WodwO3ZDt/Y/gTf2P7EQfuve7t9wJKqV+suiIiY6344YNP4mM+DkzQQNQ/gfMEsONcCljQote2C6HaTTse1gCWVU9sA3r2nzc+f3rvoWsBjLYehSapebQO4PdvhP33tx1x34eaD1gLeuP4YjhtzIR5J1attH3BEsOvZffyHeTPhAI5dM+pCPJIGorYB3Az4+MVnzc2E+8CXfkhrpEFmli5NUk3UtgsiGrHoDbj/+I5fKV2apJqobQA3Gyx6A65Z278JJA1abQN4z74ON9y146AW8A137eCPL3stG9aVrk5SHdQ2gJv9m3ALV0Jrev9N0oDU9g/u0WaDGy85eBbcjZecxah9EJIGpLYt4MxkrNU8aAzwWKvpKAhJA1Pb5l6j0eBTd+886GkYn7p7J41Gbf+TSBqw2raAN6xr8e/efAZbtk7OjYK49YoJH0cvaWBqG8AAx4w0DuqCOGbE1q+kwaltAO/e0+aKz3yfqemZuX2bxse48+pzfRqGpIGobZOvPds5KHwBpqZnaM/6NAxJg1HbAB4daSz6NIxRuyEkDUht02akEYuOAx5xJTRJA1JpAEfE+RGxIyJ2RsS1ixw/OSLujoj7I+LBiLigynrmm2k/PxX5C1e9no+8bTM33LWDmbZdEJIGo7KbcBHRBG4C3gxMAfdFxLbM3D7vtH8PfDEz/zQiNgNfA06pqqb5WiPNRacit0Z8GoakwaiyBXwOsDMzH87MNnAHcNGCcxI4tv/65cBjFdZzkA3rWtx6xcRBXRCOA5Y0SFUOQzsReHTe9hTwugXnfBT4RkS8D1gHvGmxN4qIq4CrAE4++eQVK9BxwJJKqjKAF7ubtXChhcuAz2XmH0bErwO3R8SZmdk96B9l3gLcAjAxMbEiizU4DlhSaVU2+aaAk+Ztb+KFXQxXAl8EyMzvAmuA4yusaY7jgCWVVmUA3wecFhGnRkQLuBTYtuCcfwDOA4iIX6YXwLsqrGlOa6S56Dhgb8JJGpTKAjgzZ4FrgK8DP6Y32uGhiLg+Ii7sn/YBYEtE/BD4PPDuHNB6kONjo3z6t8/2JpykYuJoW/92YmIiJycnj+g9ut1kx+PP8In/voOLzz6JDetavHL9Mfyjl48x4o04SStv0RletVyMZ/ee9twylN/Y/gTgDThJg1fL5p434CQNg1oGsDfgJA2DWgbw+NgoN19+8A24my8/m/Gx0cKVSaqTWvYBT8/s55Pf/Akfedtmjhsb5Rf97T94x1n2AUsamFoGcHu2wze2PzF3A+6A695uH7CkwallF4R9wJKGQS0D2JXQJA2DWnZBgCuhSSqvlgHsSmiShkEtm31OxJA0DGoZwN6EkzQMahnA3oSTNAxq2QcM3oSTVF4tA9ibcJKGQS2bfd6EkzQMahnA3oSTNAxqGcCuhiZpGNSyD9jV0CQNg1oGsKuhSRoGteyCsA9Y0jCoZQA7EUPSMKhlF0SjEZxxwnruvPpc2rMdWiNNNqxr0Wgs+uRoSapELVvA3W6ye0/b8JVUVO1awN1usuPxZ9iydZKp6Zm57oczTlhvCEsaqNq1gHfvac+FL/RmwG3ZOsnuPe3ClUmqm9oFsNOQJQ2L2gWwQ9AkDYvaBbBD0CQNi9rdhHMImqRhUbsWsCQNi9q1gB2GJmlY1K4F7DA0ScOidgHsMDRJw6J2AewwNEnDonYB7DA0ScOidjfhHIYmaVjULoChF8I+ekhSabUMYJejlDQMahfAjgOWNCxqdxPOccCShkXtAthxwJKGRe0C2HHAkoZF7QLYccCShkXtbsI5DljSsKhdAIPjgCUNh0q7ICLi/IjYERE7I+LaQ5zzzojYHhEPRcRfVFmPJA2TylrAEdEEbgLeDEwB90XEtszcPu+c04DfB87NzOmIeGVV9cznRAxJw6DKLohzgJ2Z+TBARNwBXARsn3fOFuCmzJwGyMwnKqwHcCKGpOFRZRfEicCj87an+vvmOx04PSLuiYh7I+L8xd4oIq6KiMmImNy1a9cRFeVEDEnDosoAXqw5mQu2R4DTgDcAlwF/FhHHveAfZd6SmROZObFx48YjKsqJGJKGRZUBPAWcNG97E/DYIuf8VWbuz8xHgB30ArkyTsSQNCyqDOD7gNMi4tSIaAGXAtsWnPOXwBsBIuJ4el0SD1dYkxMxJA2Nym7CZeZsRFwDfB1oAp/JzIci4npgMjO39Y+9JSK2Ax3gg5m5u6qawIkYkoZHZC7slh1uExMTOTk5WboMSXoxFm3h1W4tCEkaFrWbiuwkDEnDolYB7CQMScOkVl0QTsKQNExqFcBOwpA0TGoVwE7CkDRMahXATsKQNExqdRPOSRiShkmtAhh8Goak4VGrLghJGiYGsCQVUrsuCGfCSRoWtQpgZ8JJGiYvugsiIpoR8a+qKKZqzoSTNEwOGcARcWxE/H5E/ElEvCV63kdvwfR3Dq7EleNMOEnDZKkuiNuBaeC7wL8GPgi0gIsy84EB1LbiDsyEmx/CzoSTVMpSAfzqzPwVgIj4M+BJ4OTMfGYglVXgwEy4hX3AzoSTVMJSAbz/wIvM7ETEI0dz+IIz4SQNl6UC+J9GxP/j+UdpjM3bzsw8tvLqKuBMOEnD4pABnJl2jEpShQ4ZwBGxBngv8BrgQXpPNZ4dVGGStNotNQ74NmAC+BFwAfCHA6lIkmpiqT7gzfNGQfw58P3BlCRJ9bBUC3j+KAi7HiRphS3VAv7V/qgH6I18WBWjICRpWCwVwD/MzNcOrBJJqpmluiByYFVIUg0t1QJ+ZUS8/1AHM/OPKqhHkmpjqQBuAi/j+ZlwkqQVtFQA/zwzrx9YJZJUM0v1AdvylaQKLdUCPm9gVQyIz4OTNEyWWoznqUEWUjWfBydp2NTmsfQ+D07SsKlNAPs8OEnDpjYBfOB5cPP5PDhJJdUmgA88D+5ACPs8OEmlLTUKYlXxeXCShk1tAhh8Hpyk4VKbLghJGjYGsCQVYgBLUiEGsCQVYgBLUiEGsCQVUmkAR8T5EbEjInZGxLVLnHdJRGRETFRZjyQNk8oCOCKawE3AW4HNwGURsXmR89YDvwd8r6paJGkYVdkCPgfYmZkPZ2YbuAO4aJHzPgbcAOytsBZJGjpVBvCJwKPztqf6++ZExGuBkzLzq0u9UURcFRGTETG5a9eula9UkgqoMoAXW2Rh7lH3EdEAPgF84HBvlJm3ZOZEZk5s3LhxBUuUpHKqDOAp4KR525uAx+ZtrwfOBL4VET8FXg9s80acpLqoMoDvA06LiFMjogVcCmw7cDAzn87M4zPzlMw8BbgXuDAzJyusSZKGRmUBnJmzwDXA14EfA1/MzIci4vqIuLCqrytJR4vIzMOfNUQmJiZyctJGsqSjyqILjzsTTpIKMYAlqRADWJIKMYAlqRADWJIKMYAlqRADWJIKMYAlqRADWJIKMYAlqRADWJIKMYAlqRADWJIKGSldwCB1u8nuPW3asx1aI002rGvRaCy6SJEkVa42AdztJjsef4YtWyeZmp5h0/gYt14xwRknrDeEJRVRmy6I3Xvac+ELMDU9w5atk+ze0y5cmaS6qk0At2c7c+F7wNT0DO3ZTqGKJNVdbQK4NdJk0/jYQfs2jY/RGmkWqkhS3dUmgDesa3HrFRNzIXygD3jDulbhyiTVVW1uwjUawRknrOfOq891FISkoVCbAIZeCG9cf0zpMiQJqFEXhCQNGwNYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpEANYkgoxgCWpkEoDOCLOj4gdEbEzIq5d5Pj7I2J7RDwYEd+MiFdVWY8kDZPKAjgimsBNwFuBzcBlEbF5wWn3AxOZeRbwZeCGquqRpGFTZQv4HGBnZj6cmW3gDuCi+Sdk5t2Z+Vx/815gU4X1SNJQqTKATwQenbc91d93KFcCf73YgYi4KiImI2Jy165dK1iiJJVTZQDHIvty0RMjLgcmgBsXO56Zt2TmRGZObNy4cQVLlKRyRip87yngpHnbm4DHFp4UEW8CPgz8Zmbuq7AeSRoqVbaA7wNOi4hTI6IFXApsm39CRLwW+DRwYWY+UWEtkjR0KgvgzJwFrgG+DvwY+GJmPhQR10fEhf3TbgReBnwpIh6IiG2HeDtJWnUic9Fu2aE1MTGRk5OTpcuQpBdjsXtizoSTpFIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqxACWpEIMYEkqpNIAjojzI2JHROyMiGsXOX5MRHyhf/x7EXFKlfV0u8muZ/bxs+nn2PXMPrrdrPLLSdKSRqp644hoAjcBbwamgPsiYltmbp932pXAdGa+JiIuBT4O/Isq6ul2kx2PP8OWrZNMTc+waXyMW6+Y4IwT1tNoRBVfUpKWVGUL+BxgZ2Y+nJlt4A7gogXnXATc1n/9ZeC8iKgkDXfvac+FL8DU9Axbtk6ye0+7ii8nSYdVZQCfCDw6b3uqv2/RczJzFnga2LDwjSLiqoiYjIjJXbt2vaRi2rOdufCdK2h6hvZs5yW9nyQdqSoDeLGW7MJO1+WcQ2bekpkTmTmxcePGl1RMa6TJpvGxg/ZtGh+jNdJ8Se8nSUeqygCeAk6at70JeOxQ50TECPBy4KkqitmwrsWtV0zMhfCBPuAN61pVfDlJOqzKbsIB9wGnRcSpwM+AS4F/ueCcbcC7gO8ClwB/k5mVDE1oNIIzTljPnVefS3u2Q2ukyYZ1LW/ASSqmsgDOzNmIuAb4OtAEPpOZD0XE9cBkZm4D/hy4PSJ20mv5XlpVPdAL4Y3rj6nyS0jSskVFDc7KTExM5OTkZOkyJOnFWPRPbWfCSVIhBrAkFWIAS1IhBrAkFWIAS1IhBrAkFWIAS1IhBrAkFWIAS1IhBrAkFWIAS1IhR91aEBGxC/j7I3yb44EnV6CcYbIarwm8rqPJarwmWJnrejIzz1+486gL4JUQEZOZOVG6jpW0Gq8JvK6jyWq8Jqj2uuyCkKRCDGBJKqSuAXxL6QIqsBqvCbyuo8lqvCao8Lpq2QcsScOgri1gSSrOAJakQlZtAEfE+RGxIyJ2RsS1ixw/JiK+0D/+vYg4ZfBVvnjLuK73R8T2iHgwIr4ZEa8qUeeLdbjrmnfeJRGRETH0w52Wc00R8c7+9+uhiPiLQdf4UizjZ/DkiLg7Iu7v/xxeUKLOFyMiPhMRT0TE3x3ieETEJ/vX/GBE/NqKfOHMXHUf9J7C/H+AVwMt4IfA5gXnXA3c3H99KfCF0nWv0HW9EVjbf/27q+W6+uetB74N3AtMlK57Bb5XpwH3A+P97VeWrnuFrusW4Hf7rzcDPy1d9zKu6zeAXwP+7hDHLwD+mt7DNV8PfG8lvu5qbQGfA+zMzIczsw3cAVy04JyLgNv6r78MnBcRiz65dIgc9roy8+7MfK6/eS+wacA1vhTL+X4BfAy4Adg7yOJeouVc0xbgpsycBsjMJwZc40uxnOtK4Nj+65cDjw2wvpckM78NPLXEKRcBW7PnXuC4iPilI/26qzWATwQenbc91d+36DmZOQs8DWwYSHUv3XKua74r6f1fe9gd9roi4rXASZn51UEWdgSW8706HTg9Iu6JiHsj4gVTVYfQcq7ro8DlETEFfA1432BKq9SL/d1blpEjfYMhtVhLduF4u+WcM2yWXXNEXA5MAL9ZaUUrY8nriogG8Ang3YMqaAUs53s1Qq8b4g30/lL524g4MzN/UXFtR2I513UZ8LnM/MOI+HXg9v51dasvrzKV5MVqbQFPASfN297EC/8MmjsnIkbo/am01J8gw2A510VEvAn4MHBhZu4bUG1H4nDXtR44E/hWRPyUXh/ctiG/Ebfcn8G/ysz9mfkIsINeIA+z5VzXlcAXATLzu8AaegvaHM2W9bv3Yq3WAL4POC0iTo2IFr2bbNsWnLMNeFf/9SXA32S/t32IHfa6+n+qf5pe+B4NfYpwmOvKzKcz8/jMPCUzT6HXt31hZk6WKXdZlvMz+Jf0bpoSEcfT65J4eKBVvnjLua5/AM4DiIhfphfAuwZa5crbBlzRHw3xeuDpzPz5Eb9r6buPFd7VvAD4Cb07th/u77ue3i8u9H4ovgTsBL4PvLp0zSt0Xf8DeBx4oP+xrXTNK3FdC879FkM+CmKZ36sA/gjYDvwIuLR0zSt0XZuBe+iNkHgAeEvpmpdxTZ8Hfg7sp9favRJ4L/Deed+rm/rX/KOV+vlzKrIkFbJauyAkaegZwJJUiAEsSYUYwJJUiAEsSYUYwKqNiOhExAPzPk6JiDdExNP9lbt+HBHX9c+dv/9/R8R/LV2/Vp/VOhVZWsxMZv7q/B39ZUj/NjPfFhHrgAci4sB6Ewf2jwH3R8SdmXnPYEvWamYLWOrLzD3AD4B/vGD/DL0JBUe8+Io0nwGsOhmb1/1w58KDEbGB3joTDy3YP05vjYZvD6ZM1YVdEKqTF3RB9P3ziLgf6AL/JTMfiog39Pc/CJzR3/9/B1irasAAlvp9vYfaHxGnA/+z3wf8wKCL0+plF4R0GJn5E+A/Ax8qXYtWFwNYWp6bgd+IiFNLF6LVw9XQJKkQW8CSVIgBLEmFGMCSVIgBLEmFGMCSVIgBLEmFGMCSVMj/B58GBVbAc1uJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.relplot(data=ROC_train_df,x='FPR',y='TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test AUC is : \n",
      " 0.9710219093333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "auc_test = metrics.auc(ROC_df['FPR'],ROC_df['TPR'])\n",
    "\n",
    "print('The test AUC is : \\n', auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train AUC is : \n",
      " 0.9923615254237288\n"
     ]
    }
   ],
   "source": [
    "auc_train = metrics.auc(ROC_train_df['FPR'],ROC_train_df['TPR'])\n",
    "\n",
    "print('The train AUC is : \\n', auc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification for Training set out of 60000 is : \n",
      " 1849\n",
      "Misclassification for Test set out of 16000 is : \n",
      " 539\n"
     ]
    }
   ],
   "source": [
    "train_mis = 0\n",
    "for i in np.arange(0,60000):\n",
    "    if y_train_predicted[i] != y_train[i]:\n",
    "        train_mis = train_mis + 1\n",
    "\n",
    "test_mis = 0\n",
    "for i in np.arange(0,16000):\n",
    "    if y_test_predicted[i] != y_test[i]:\n",
    "        test_mis = test_mis + 1\n",
    "        \n",
    "print('Misclassification for Training set out of 60000 is : \\n',train_mis)\n",
    "print('Misclassification for Test set out of 16000 is : \\n',test_mis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few comments :\n",
    "\n",
    "Since we apply SMOTE in the last part of the assignment, which is a hybrid of up and down sampling, here we've used the penalization method to try and take care of class imbalance\n",
    "\n",
    "Undoubtedly, it is clear that the overall error has increased, however this error is approximately uniformly distributed between classes 0 and 1\n",
    "\n",
    "The test confusion matrix shows that of the 375 1's we correctly classify 324 1's, much higher than obtained without penalization. \n",
    "\n",
    "Of the 15625 0's, we've correctly classified 15137 0's. This number has gone down from 15609, however is still sufficiently accurate, especially given that we've taken care of, to a certain extent, of the class imbalance.\n",
    "\n",
    "The 1's correctly classified in % are now : 86.4 %\n",
    "This is significant improvement from 70 % in the previous case\n",
    "\n",
    "Other than the change in class weights, everything has been kept the same\n",
    "\n",
    "NOTE :\n",
    "The class weights were chosen here heuristically. We could obtain class weights via cross-validation, that is,\n",
    "\n",
    "We first pick a range of weights for 0 and for 1 (these ranges are integral logarithmically, and thus are obtained in scales of 10^x, or in scales of 10, much like lambda in Lasso/Ridge Regression)\n",
    "\n",
    "Then we could pick all possible combinations between the two ranges and see which one minimizes the extent of class balance by selecting appropriate criterions (such as total 1's classified correctly, total 0's classified correctly, and over error rate)\n",
    "\n",
    "However for simplicity we have not used CV here, and again picked the weights via trial and error\n",
    "\n",
    "As such, applying CV would just mean looping using two for loops, one for weight of class 0 and other for class 1, and fitting the model for each weight set selected. Obviously this would take quite a while to compute and thus hasn't been performed\n",
    "\n",
    "THUS\n",
    "Weights should be selected by CV\n",
    "Here, to save computation time they've been picked heuristically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
